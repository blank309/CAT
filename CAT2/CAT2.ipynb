{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"AI-DataTrain.csv\")\n",
    "data2 = pd.read_csv(\"AI-DataTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>...</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>Q45</th>\n",
       "      <th>Q46</th>\n",
       "      <th>Q47</th>\n",
       "      <th>Q48</th>\n",
       "      <th>Q49</th>\n",
       "      <th>Q50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num  Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  ...  Q41  Q42  Q43  Q44  Q45  Q46  \\\n",
       "0    0   0   1   0   0   0   0   0   1   0  ...    0    0    1    1    1    0   \n",
       "1    1   1   1   0   1   0   0   0   1   0  ...    0    1    0    0    0    0   \n",
       "2    2   1   1   0   0   1   0   1   1   0  ...    1    1    0    0    1    0   \n",
       "3    3   1   1   0   0   1   1   1   0   0  ...    0    0    0    1    1    0   \n",
       "4    4   1   0   0   1   1   0   0   1   0  ...    1    0    1    1    1    0   \n",
       "\n",
       "   Q47  Q48  Q49  Q50  \n",
       "0    0    0    1    1  \n",
       "1    0    0    0    0  \n",
       "2    1    0    1    1  \n",
       "3    0    0    1    0  \n",
       "4    1    0    1    1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>...</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  Q18  Q19  ...  Q25  Q26  Q27  Q28  \\\n",
       "0    0    0    1    0    1    0    0    1    1    1  ...    0    1    0    0   \n",
       "1    1    0    1    0    1    0    1    1    1    1  ...    1    1    1    0   \n",
       "2    0    0    1    0    1    0    0    0    1    1  ...    0    1    0    0   \n",
       "3    1    1    0    0    1    0    0    0    1    0  ...    1    1    0    1   \n",
       "4    0    1    0    1    0    0    1    0    1    1  ...    0    1    0    1   \n",
       "\n",
       "   Q29  Q30  Q31  Q32  Q33  Q34  \n",
       "0    1    1    1    1    1    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    1    1    0    1    0    0  \n",
       "3    0    1    0    1    1    1  \n",
       "4    1    1    0    1    0    1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = data2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = head.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop('Num',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>...</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>Q45</th>\n",
       "      <th>Q46</th>\n",
       "      <th>Q47</th>\n",
       "      <th>Q48</th>\n",
       "      <th>Q49</th>\n",
       "      <th>Q50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num  Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  ...  Q41  Q42  Q43  Q44  Q45  Q46  \\\n",
       "0    0   0   1   0   0   0   0   0   1   0  ...    0    0    1    1    1    0   \n",
       "1    1   1   1   0   1   0   0   0   1   0  ...    0    1    0    0    0    0   \n",
       "2    2   1   1   0   0   1   0   1   1   0  ...    1    1    0    0    1    0   \n",
       "3    3   1   1   0   0   1   1   1   0   0  ...    0    0    0    1    1    0   \n",
       "4    4   1   0   0   1   1   0   0   1   0  ...    1    0    1    1    1    0   \n",
       "\n",
       "   Q47  Q48  Q49  Q50  \n",
       "0    0    0    1    1  \n",
       "1    0    0    0    0  \n",
       "2    1    0    1    1  \n",
       "3    0    0    1    0  \n",
       "4    1    0    1    1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values\n",
    "data2 = data2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 51\n",
      "50 25\n"
     ]
    }
   ],
   "source": [
    "[m,n] = data.shape\n",
    "print(m,n)\n",
    "[l,p] = data2.shape\n",
    "print(l,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "def prob(data,i,list,row):\n",
    "    pb = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for j in range(0,row,1):\n",
    "        if data[j,i]==1:\n",
    "            count = count + 1\n",
    "        total = total + 1\n",
    "    pb = count/total\n",
    "    list.append(pb)\n",
    "    \n",
    "def inter(data,k,list,row):\n",
    "    for i in range(0,k,1):\n",
    "        prob(data,i,list,row)\n",
    "        \n",
    "inter(data,n,list1,m)\n",
    "inter(data2,p,list2,l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "Y_test = []\n",
    "def weights(lt,Y,colm):\n",
    "    for i in range(0,colm,1):\n",
    "        if lt[i] > 0.750:\n",
    "            Y.append(3)\n",
    "        elif lt[i] > 0.50 and lt[i] < 0.749:\n",
    "            Y.append(2)\n",
    "        elif lt[i] > 0.25 and lt[i] < 0.499:\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "weights(list2,Y_test,p)\n",
    "weights(list1,Y_train,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(list1)\n",
    "X_test = np.array(list2)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95 and logs.get('loss')<0.35):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(12, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(6, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51 samples, validate on 25 samples\n",
      "Epoch 1/2000\n",
      "51/51 [==============================] - 2s 48ms/sample - loss: 1.4242 - accuracy: 0.0784 - val_loss: 1.4309 - val_accuracy: 0.0800\n",
      "Epoch 2/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.4191 - accuracy: 0.0784 - val_loss: 1.4272 - val_accuracy: 0.0800\n",
      "Epoch 3/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.4157 - accuracy: 0.0784 - val_loss: 1.4236 - val_accuracy: 0.0800\n",
      "Epoch 4/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.4117 - accuracy: 0.0784 - val_loss: 1.4201 - val_accuracy: 0.0800\n",
      "Epoch 5/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.4076 - accuracy: 0.0784 - val_loss: 1.4167 - val_accuracy: 0.0800\n",
      "Epoch 6/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.4033 - accuracy: 0.0784 - val_loss: 1.4134 - val_accuracy: 0.0800\n",
      "Epoch 7/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3997 - accuracy: 0.0784 - val_loss: 1.4101 - val_accuracy: 0.0800\n",
      "Epoch 8/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3957 - accuracy: 0.0784 - val_loss: 1.4068 - val_accuracy: 0.0800\n",
      "Epoch 9/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3919 - accuracy: 0.0784 - val_loss: 1.4036 - val_accuracy: 0.0800\n",
      "Epoch 10/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3880 - accuracy: 0.0784 - val_loss: 1.4004 - val_accuracy: 0.0800\n",
      "Epoch 11/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3840 - accuracy: 0.0784 - val_loss: 1.3972 - val_accuracy: 0.0800\n",
      "Epoch 12/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3809 - accuracy: 0.0784 - val_loss: 1.3941 - val_accuracy: 0.0800\n",
      "Epoch 13/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3774 - accuracy: 0.0784 - val_loss: 1.3910 - val_accuracy: 0.0800\n",
      "Epoch 14/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3736 - accuracy: 0.0784 - val_loss: 1.3880 - val_accuracy: 0.0800\n",
      "Epoch 15/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3698 - accuracy: 0.0784 - val_loss: 1.3851 - val_accuracy: 0.0800\n",
      "Epoch 16/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3666 - accuracy: 0.0784 - val_loss: 1.3822 - val_accuracy: 0.0800\n",
      "Epoch 17/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 1.3634 - accuracy: 0.0784 - val_loss: 1.3794 - val_accuracy: 0.0800\n",
      "Epoch 18/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.3598 - accuracy: 0.0784 - val_loss: 1.3766 - val_accuracy: 0.0800\n",
      "Epoch 19/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.3571 - accuracy: 0.0784 - val_loss: 1.3738 - val_accuracy: 0.0800\n",
      "Epoch 20/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3533 - accuracy: 0.0784 - val_loss: 1.3712 - val_accuracy: 0.0800\n",
      "Epoch 21/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3506 - accuracy: 0.0784 - val_loss: 1.3685 - val_accuracy: 0.0800\n",
      "Epoch 22/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3476 - accuracy: 0.0784 - val_loss: 1.3660 - val_accuracy: 0.0800\n",
      "Epoch 23/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3446 - accuracy: 0.0784 - val_loss: 1.3636 - val_accuracy: 0.0800\n",
      "Epoch 24/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3415 - accuracy: 0.1373 - val_loss: 1.3613 - val_accuracy: 0.1200\n",
      "Epoch 25/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3388 - accuracy: 0.2745 - val_loss: 1.3590 - val_accuracy: 0.2000\n",
      "Epoch 26/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3359 - accuracy: 0.3333 - val_loss: 1.3568 - val_accuracy: 0.2400\n",
      "Epoch 27/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3332 - accuracy: 0.3529 - val_loss: 1.3546 - val_accuracy: 0.3600\n",
      "Epoch 28/2000\n",
      "51/51 [==============================] - 0s 2ms/sample - loss: 1.3308 - accuracy: 0.3529 - val_loss: 1.3525 - val_accuracy: 0.4000\n",
      "Epoch 29/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3277 - accuracy: 0.4902 - val_loss: 1.3504 - val_accuracy: 0.4400\n",
      "Epoch 30/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3252 - accuracy: 0.5294 - val_loss: 1.3484 - val_accuracy: 0.4400\n",
      "Epoch 31/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3226 - accuracy: 0.5098 - val_loss: 1.3464 - val_accuracy: 0.4000\n",
      "Epoch 32/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3203 - accuracy: 0.4902 - val_loss: 1.3444 - val_accuracy: 0.4000\n",
      "Epoch 33/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3171 - accuracy: 0.4706 - val_loss: 1.3425 - val_accuracy: 0.4000\n",
      "Epoch 34/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3152 - accuracy: 0.4510 - val_loss: 1.3406 - val_accuracy: 0.4000\n",
      "Epoch 35/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3128 - accuracy: 0.4510 - val_loss: 1.3388 - val_accuracy: 0.4000\n",
      "Epoch 36/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 1.3101 - accuracy: 0.4510 - val_loss: 1.3370 - val_accuracy: 0.4000\n",
      "Epoch 37/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3074 - accuracy: 0.4510 - val_loss: 1.3353 - val_accuracy: 0.4000\n",
      "Epoch 38/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3053 - accuracy: 0.4510 - val_loss: 1.3336 - val_accuracy: 0.4000\n",
      "Epoch 39/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.3030 - accuracy: 0.4510 - val_loss: 1.3318 - val_accuracy: 0.4000\n",
      "Epoch 40/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.3010 - accuracy: 0.4510 - val_loss: 1.3301 - val_accuracy: 0.4000\n",
      "Epoch 41/2000\n",
      "51/51 [==============================] - 0s 2ms/sample - loss: 1.2983 - accuracy: 0.4510 - val_loss: 1.3285 - val_accuracy: 0.4000\n",
      "Epoch 42/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.2958 - accuracy: 0.4510 - val_loss: 1.3269 - val_accuracy: 0.4000\n",
      "Epoch 43/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2939 - accuracy: 0.4510 - val_loss: 1.3253 - val_accuracy: 0.4000\n",
      "Epoch 44/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2914 - accuracy: 0.4510 - val_loss: 1.3237 - val_accuracy: 0.4000\n",
      "Epoch 45/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2890 - accuracy: 0.4510 - val_loss: 1.3221 - val_accuracy: 0.4000\n",
      "Epoch 46/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2871 - accuracy: 0.4510 - val_loss: 1.3205 - val_accuracy: 0.4000\n",
      "Epoch 47/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 1.2851 - accuracy: 0.4510 - val_loss: 1.3189 - val_accuracy: 0.4000\n",
      "Epoch 48/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2824 - accuracy: 0.4510 - val_loss: 1.3173 - val_accuracy: 0.4000\n",
      "Epoch 49/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2801 - accuracy: 0.4510 - val_loss: 1.3157 - val_accuracy: 0.4000\n",
      "Epoch 50/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.2784 - accuracy: 0.4510 - val_loss: 1.3142 - val_accuracy: 0.4000\n",
      "Epoch 51/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.2759 - accuracy: 0.4510 - val_loss: 1.3126 - val_accuracy: 0.4000\n",
      "Epoch 52/2000\n",
      "51/51 [==============================] - 0s 941us/sample - loss: 1.2736 - accuracy: 0.4510 - val_loss: 1.3111 - val_accuracy: 0.4000\n",
      "Epoch 53/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2714 - accuracy: 0.4510 - val_loss: 1.3095 - val_accuracy: 0.4000\n",
      "Epoch 54/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2695 - accuracy: 0.4510 - val_loss: 1.3079 - val_accuracy: 0.4000\n",
      "Epoch 55/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2674 - accuracy: 0.4510 - val_loss: 1.3064 - val_accuracy: 0.4000\n",
      "Epoch 56/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 1.2651 - accuracy: 0.4510 - val_loss: 1.3049 - val_accuracy: 0.4000\n",
      "Epoch 57/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2630 - accuracy: 0.4510 - val_loss: 1.3034 - val_accuracy: 0.4000\n",
      "Epoch 58/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2612 - accuracy: 0.4510 - val_loss: 1.3019 - val_accuracy: 0.4000\n",
      "Epoch 59/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2588 - accuracy: 0.4510 - val_loss: 1.3004 - val_accuracy: 0.4000\n",
      "Epoch 60/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2568 - accuracy: 0.4510 - val_loss: 1.2989 - val_accuracy: 0.4000\n",
      "Epoch 61/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2551 - accuracy: 0.4510 - val_loss: 1.2974 - val_accuracy: 0.4000\n",
      "Epoch 62/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2534 - accuracy: 0.4510 - val_loss: 1.2959 - val_accuracy: 0.4000\n",
      "Epoch 63/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2511 - accuracy: 0.4510 - val_loss: 1.2944 - val_accuracy: 0.4000\n",
      "Epoch 64/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2491 - accuracy: 0.4510 - val_loss: 1.2929 - val_accuracy: 0.4000\n",
      "Epoch 65/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2472 - accuracy: 0.4510 - val_loss: 1.2914 - val_accuracy: 0.4000\n",
      "Epoch 66/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2457 - accuracy: 0.4510 - val_loss: 1.2899 - val_accuracy: 0.4000\n",
      "Epoch 67/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2434 - accuracy: 0.4510 - val_loss: 1.2884 - val_accuracy: 0.4000\n",
      "Epoch 68/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2418 - accuracy: 0.4510 - val_loss: 1.2869 - val_accuracy: 0.4000\n",
      "Epoch 69/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2398 - accuracy: 0.4510 - val_loss: 1.2854 - val_accuracy: 0.4000\n",
      "Epoch 70/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2380 - accuracy: 0.4510 - val_loss: 1.2839 - val_accuracy: 0.4000\n",
      "Epoch 71/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2360 - accuracy: 0.4510 - val_loss: 1.2824 - val_accuracy: 0.4000\n",
      "Epoch 72/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2343 - accuracy: 0.4510 - val_loss: 1.2809 - val_accuracy: 0.4000\n",
      "Epoch 73/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2322 - accuracy: 0.4510 - val_loss: 1.2795 - val_accuracy: 0.4000\n",
      "Epoch 74/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2303 - accuracy: 0.4510 - val_loss: 1.2780 - val_accuracy: 0.4000\n",
      "Epoch 75/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2285 - accuracy: 0.4510 - val_loss: 1.2767 - val_accuracy: 0.4000\n",
      "Epoch 76/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2267 - accuracy: 0.4510 - val_loss: 1.2755 - val_accuracy: 0.4000\n",
      "Epoch 77/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2246 - accuracy: 0.4510 - val_loss: 1.2742 - val_accuracy: 0.4000\n",
      "Epoch 78/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2231 - accuracy: 0.4510 - val_loss: 1.2730 - val_accuracy: 0.4000\n",
      "Epoch 79/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 1.2214 - accuracy: 0.4510 - val_loss: 1.2718 - val_accuracy: 0.4000\n",
      "Epoch 80/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.2195 - accuracy: 0.4510 - val_loss: 1.2707 - val_accuracy: 0.4000\n",
      "Epoch 81/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.2180 - accuracy: 0.4510 - val_loss: 1.2696 - val_accuracy: 0.4000\n",
      "Epoch 82/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.2164 - accuracy: 0.4510 - val_loss: 1.2685 - val_accuracy: 0.4000\n",
      "Epoch 83/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.2147 - accuracy: 0.4510 - val_loss: 1.2673 - val_accuracy: 0.4000\n",
      "Epoch 84/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 1.2131 - accuracy: 0.4510 - val_loss: 1.2662 - val_accuracy: 0.4000\n",
      "Epoch 85/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.2113 - accuracy: 0.4510 - val_loss: 1.2651 - val_accuracy: 0.4000\n",
      "Epoch 86/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.2098 - accuracy: 0.4510 - val_loss: 1.2639 - val_accuracy: 0.4000\n",
      "Epoch 87/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.2081 - accuracy: 0.4510 - val_loss: 1.2627 - val_accuracy: 0.4000\n",
      "Epoch 88/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 1.2064 - accuracy: 0.4510 - val_loss: 1.2616 - val_accuracy: 0.4000\n",
      "Epoch 89/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.2049 - accuracy: 0.4510 - val_loss: 1.2604 - val_accuracy: 0.4000\n",
      "Epoch 90/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 1.2034 - accuracy: 0.4510 - val_loss: 1.2592 - val_accuracy: 0.4000\n",
      "Epoch 91/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.2016 - accuracy: 0.4510 - val_loss: 1.2581 - val_accuracy: 0.4000\n",
      "Epoch 92/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.2000 - accuracy: 0.4510 - val_loss: 1.2569 - val_accuracy: 0.4000\n",
      "Epoch 93/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.1984 - accuracy: 0.4510 - val_loss: 1.2558 - val_accuracy: 0.4000\n",
      "Epoch 94/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1968 - accuracy: 0.4510 - val_loss: 1.2548 - val_accuracy: 0.4000\n",
      "Epoch 95/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1951 - accuracy: 0.4510 - val_loss: 1.2537 - val_accuracy: 0.4000\n",
      "Epoch 96/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1936 - accuracy: 0.4510 - val_loss: 1.2526 - val_accuracy: 0.4000\n",
      "Epoch 97/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1918 - accuracy: 0.4510 - val_loss: 1.2515 - val_accuracy: 0.4000\n",
      "Epoch 98/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.1982 - accuracy: 0.43 - 0s 903us/sample - loss: 1.1903 - accuracy: 0.4510 - val_loss: 1.2505 - val_accuracy: 0.4000\n",
      "Epoch 99/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1888 - accuracy: 0.4510 - val_loss: 1.2494 - val_accuracy: 0.4000\n",
      "Epoch 100/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1872 - accuracy: 0.4510 - val_loss: 1.2483 - val_accuracy: 0.4000\n",
      "Epoch 101/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1854 - accuracy: 0.4510 - val_loss: 1.2471 - val_accuracy: 0.4000\n",
      "Epoch 102/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1838 - accuracy: 0.4510 - val_loss: 1.2459 - val_accuracy: 0.4000\n",
      "Epoch 103/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 1.1824 - accuracy: 0.4510 - val_loss: 1.2448 - val_accuracy: 0.4000\n",
      "Epoch 104/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1806 - accuracy: 0.4510 - val_loss: 1.2435 - val_accuracy: 0.4000\n",
      "Epoch 105/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1791 - accuracy: 0.4510 - val_loss: 1.2423 - val_accuracy: 0.4000\n",
      "Epoch 106/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.1774 - accuracy: 0.4510 - val_loss: 1.2411 - val_accuracy: 0.4000\n",
      "Epoch 107/2000\n",
      "51/51 [==============================] - 0s 882us/sample - loss: 1.1758 - accuracy: 0.4510 - val_loss: 1.2399 - val_accuracy: 0.4000\n",
      "Epoch 108/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.1741 - accuracy: 0.4510 - val_loss: 1.2385 - val_accuracy: 0.4000\n",
      "Epoch 109/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 1.1725 - accuracy: 0.4510 - val_loss: 1.2371 - val_accuracy: 0.4000\n",
      "Epoch 110/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1709 - accuracy: 0.4510 - val_loss: 1.2358 - val_accuracy: 0.4000\n",
      "Epoch 111/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1692 - accuracy: 0.4510 - val_loss: 1.2344 - val_accuracy: 0.4000\n",
      "Epoch 112/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1676 - accuracy: 0.4510 - val_loss: 1.2330 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1658 - accuracy: 0.4510 - val_loss: 1.2316 - val_accuracy: 0.4000\n",
      "Epoch 114/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 1.1642 - accuracy: 0.4510 - val_loss: 1.2301 - val_accuracy: 0.4000\n",
      "Epoch 115/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1624 - accuracy: 0.4510 - val_loss: 1.2286 - val_accuracy: 0.4000\n",
      "Epoch 116/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1606 - accuracy: 0.4510 - val_loss: 1.2270 - val_accuracy: 0.4000\n",
      "Epoch 117/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1589 - accuracy: 0.4510 - val_loss: 1.2252 - val_accuracy: 0.4000\n",
      "Epoch 118/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1571 - accuracy: 0.4510 - val_loss: 1.2231 - val_accuracy: 0.4000\n",
      "Epoch 119/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1550 - accuracy: 0.4510 - val_loss: 1.2211 - val_accuracy: 0.4000\n",
      "Epoch 120/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1530 - accuracy: 0.4510 - val_loss: 1.2190 - val_accuracy: 0.4000\n",
      "Epoch 121/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.1512 - accuracy: 0.4510 - val_loss: 1.2170 - val_accuracy: 0.4000\n",
      "Epoch 122/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.1494 - accuracy: 0.4510 - val_loss: 1.2150 - val_accuracy: 0.4000\n",
      "Epoch 123/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.1476 - accuracy: 0.4510 - val_loss: 1.2130 - val_accuracy: 0.4000\n",
      "Epoch 124/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 1.1456 - accuracy: 0.4510 - val_loss: 1.2111 - val_accuracy: 0.4000\n",
      "Epoch 125/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1437 - accuracy: 0.4510 - val_loss: 1.2092 - val_accuracy: 0.4000\n",
      "Epoch 126/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1420 - accuracy: 0.4510 - val_loss: 1.2073 - val_accuracy: 0.4000\n",
      "Epoch 127/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1400 - accuracy: 0.4510 - val_loss: 1.2055 - val_accuracy: 0.4000\n",
      "Epoch 128/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1381 - accuracy: 0.4510 - val_loss: 1.2038 - val_accuracy: 0.4000\n",
      "Epoch 129/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1362 - accuracy: 0.4510 - val_loss: 1.2022 - val_accuracy: 0.4000\n",
      "Epoch 130/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1343 - accuracy: 0.4510 - val_loss: 1.2006 - val_accuracy: 0.4000\n",
      "Epoch 131/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.1322 - accuracy: 0.4510 - val_loss: 1.1991 - val_accuracy: 0.4000\n",
      "Epoch 132/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.1303 - accuracy: 0.4510 - val_loss: 1.1976 - val_accuracy: 0.4000\n",
      "Epoch 133/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1284 - accuracy: 0.4510 - val_loss: 1.1962 - val_accuracy: 0.4000\n",
      "Epoch 134/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1266 - accuracy: 0.4510 - val_loss: 1.1947 - val_accuracy: 0.4000\n",
      "Epoch 135/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1245 - accuracy: 0.4510 - val_loss: 1.1931 - val_accuracy: 0.4000\n",
      "Epoch 136/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1227 - accuracy: 0.4510 - val_loss: 1.1912 - val_accuracy: 0.4000\n",
      "Epoch 137/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1210 - accuracy: 0.4510 - val_loss: 1.1891 - val_accuracy: 0.4000\n",
      "Epoch 138/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.1188 - accuracy: 0.4510 - val_loss: 1.1874 - val_accuracy: 0.4000\n",
      "Epoch 139/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1169 - accuracy: 0.4510 - val_loss: 1.1856 - val_accuracy: 0.4000\n",
      "Epoch 140/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.1149 - accuracy: 0.4510 - val_loss: 1.1837 - val_accuracy: 0.4000\n",
      "Epoch 141/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1130 - accuracy: 0.4510 - val_loss: 1.1817 - val_accuracy: 0.4000\n",
      "Epoch 142/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1112 - accuracy: 0.4510 - val_loss: 1.1799 - val_accuracy: 0.4000\n",
      "Epoch 143/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.1092 - accuracy: 0.4510 - val_loss: 1.1781 - val_accuracy: 0.4000\n",
      "Epoch 144/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1073 - accuracy: 0.4510 - val_loss: 1.1763 - val_accuracy: 0.4000\n",
      "Epoch 145/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.1053 - accuracy: 0.4510 - val_loss: 1.1745 - val_accuracy: 0.4000\n",
      "Epoch 146/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.1034 - accuracy: 0.4510 - val_loss: 1.1727 - val_accuracy: 0.4000\n",
      "Epoch 147/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.1015 - accuracy: 0.4510 - val_loss: 1.1708 - val_accuracy: 0.4000\n",
      "Epoch 148/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0998 - accuracy: 0.4510 - val_loss: 1.1690 - val_accuracy: 0.4000\n",
      "Epoch 149/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0979 - accuracy: 0.4510 - val_loss: 1.1673 - val_accuracy: 0.4000\n",
      "Epoch 150/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0959 - accuracy: 0.4510 - val_loss: 1.1654 - val_accuracy: 0.4000\n",
      "Epoch 151/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 1.0940 - accuracy: 0.4510 - val_loss: 1.1635 - val_accuracy: 0.4000\n",
      "Epoch 152/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0922 - accuracy: 0.4510 - val_loss: 1.1614 - val_accuracy: 0.4000\n",
      "Epoch 153/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0903 - accuracy: 0.4510 - val_loss: 1.1596 - val_accuracy: 0.4000\n",
      "Epoch 154/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 1.0884 - accuracy: 0.4510 - val_loss: 1.1580 - val_accuracy: 0.4000\n",
      "Epoch 155/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0865 - accuracy: 0.4510 - val_loss: 1.1564 - val_accuracy: 0.4000\n",
      "Epoch 156/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0847 - accuracy: 0.4510 - val_loss: 1.1547 - val_accuracy: 0.4000\n",
      "Epoch 157/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 1.0828 - accuracy: 0.4510 - val_loss: 1.1528 - val_accuracy: 0.4000\n",
      "Epoch 158/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.0808 - accuracy: 0.4510 - val_loss: 1.1509 - val_accuracy: 0.4000\n",
      "Epoch 159/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0789 - accuracy: 0.4510 - val_loss: 1.1491 - val_accuracy: 0.4000\n",
      "Epoch 160/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0773 - accuracy: 0.4510 - val_loss: 1.1474 - val_accuracy: 0.4000\n",
      "Epoch 161/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0752 - accuracy: 0.4510 - val_loss: 1.1457 - val_accuracy: 0.4000\n",
      "Epoch 162/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0634 - accuracy: 0.46 - 0s 883us/sample - loss: 1.0733 - accuracy: 0.4510 - val_loss: 1.1440 - val_accuracy: 0.4000\n",
      "Epoch 163/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0715 - accuracy: 0.4510 - val_loss: 1.1422 - val_accuracy: 0.4000\n",
      "Epoch 164/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.0696 - accuracy: 0.4510 - val_loss: 1.1404 - val_accuracy: 0.4000\n",
      "Epoch 165/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.0675 - accuracy: 0.4510 - val_loss: 1.1387 - val_accuracy: 0.4000\n",
      "Epoch 166/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0659 - accuracy: 0.4510 - val_loss: 1.1368 - val_accuracy: 0.4000\n",
      "Epoch 167/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0640 - accuracy: 0.4510 - val_loss: 1.1353 - val_accuracy: 0.4000\n",
      "Epoch 168/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 942us/sample - loss: 1.0621 - accuracy: 0.4510 - val_loss: 1.1338 - val_accuracy: 0.4000\n",
      "Epoch 169/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0602 - accuracy: 0.4510 - val_loss: 1.1318 - val_accuracy: 0.4000\n",
      "Epoch 170/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 1.0584 - accuracy: 0.4510 - val_loss: 1.1301 - val_accuracy: 0.4000\n",
      "Epoch 171/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0565 - accuracy: 0.4510 - val_loss: 1.1285 - val_accuracy: 0.4000\n",
      "Epoch 172/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0545 - accuracy: 0.4510 - val_loss: 1.1272 - val_accuracy: 0.4000\n",
      "Epoch 173/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 1.0527 - accuracy: 0.4510 - val_loss: 1.1259 - val_accuracy: 0.4000\n",
      "Epoch 174/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0512 - accuracy: 0.4510 - val_loss: 1.1247 - val_accuracy: 0.4000\n",
      "Epoch 175/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 1.0491 - accuracy: 0.4510 - val_loss: 1.1232 - val_accuracy: 0.4000\n",
      "Epoch 176/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0473 - accuracy: 0.4510 - val_loss: 1.1216 - val_accuracy: 0.4000\n",
      "Epoch 177/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0457 - accuracy: 0.4510 - val_loss: 1.1199 - val_accuracy: 0.4000\n",
      "Epoch 178/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0440 - accuracy: 0.4510 - val_loss: 1.1181 - val_accuracy: 0.4000\n",
      "Epoch 179/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 1.0419 - accuracy: 0.4510 - val_loss: 1.1165 - val_accuracy: 0.4000\n",
      "Epoch 180/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 1.0401 - accuracy: 0.4510 - val_loss: 1.1150 - val_accuracy: 0.4000\n",
      "Epoch 181/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0384 - accuracy: 0.4510 - val_loss: 1.1133 - val_accuracy: 0.4000\n",
      "Epoch 182/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 1.0366 - accuracy: 0.4510 - val_loss: 1.1115 - val_accuracy: 0.4000\n",
      "Epoch 183/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 1.0349 - accuracy: 0.4706 - val_loss: 1.1096 - val_accuracy: 0.4000\n",
      "Epoch 184/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0329 - accuracy: 0.4706 - val_loss: 1.1078 - val_accuracy: 0.4000\n",
      "Epoch 185/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0313 - accuracy: 0.4706 - val_loss: 1.1059 - val_accuracy: 0.4000\n",
      "Epoch 186/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 1.0295 - accuracy: 0.4902 - val_loss: 1.1041 - val_accuracy: 0.4400\n",
      "Epoch 187/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 1.0276 - accuracy: 0.4902 - val_loss: 1.1023 - val_accuracy: 0.4400\n",
      "Epoch 188/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 1.0258 - accuracy: 0.4902 - val_loss: 1.1002 - val_accuracy: 0.4400\n",
      "Epoch 189/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0239 - accuracy: 0.4902 - val_loss: 1.0982 - val_accuracy: 0.4400\n",
      "Epoch 190/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0223 - accuracy: 0.4902 - val_loss: 1.0961 - val_accuracy: 0.4400\n",
      "Epoch 191/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0204 - accuracy: 0.4902 - val_loss: 1.0941 - val_accuracy: 0.4400\n",
      "Epoch 192/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 1.0185 - accuracy: 0.4902 - val_loss: 1.0921 - val_accuracy: 0.4400\n",
      "Epoch 193/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0169 - accuracy: 0.4902 - val_loss: 1.0902 - val_accuracy: 0.4400\n",
      "Epoch 194/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0151 - accuracy: 0.5098 - val_loss: 1.0886 - val_accuracy: 0.4800\n",
      "Epoch 195/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 1.0134 - accuracy: 0.5098 - val_loss: 1.0870 - val_accuracy: 0.4800\n",
      "Epoch 196/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0114 - accuracy: 0.5098 - val_loss: 1.0856 - val_accuracy: 0.4800\n",
      "Epoch 197/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 1.0097 - accuracy: 0.5294 - val_loss: 1.0841 - val_accuracy: 0.4800\n",
      "Epoch 198/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0080 - accuracy: 0.5294 - val_loss: 1.0827 - val_accuracy: 0.4800\n",
      "Epoch 199/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 1.0062 - accuracy: 0.5490 - val_loss: 1.0810 - val_accuracy: 0.4800\n",
      "Epoch 200/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 1.0046 - accuracy: 0.5490 - val_loss: 1.0789 - val_accuracy: 0.4800\n",
      "Epoch 201/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 1.0026 - accuracy: 0.5686 - val_loss: 1.0772 - val_accuracy: 0.4800\n",
      "Epoch 202/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.0008 - accuracy: 0.5686 - val_loss: 1.0754 - val_accuracy: 0.4800\n",
      "Epoch 203/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9992 - accuracy: 0.5686 - val_loss: 1.0736 - val_accuracy: 0.4800\n",
      "Epoch 204/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.9974 - accuracy: 0.5686 - val_loss: 1.0716 - val_accuracy: 0.4800\n",
      "Epoch 205/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9956 - accuracy: 0.5686 - val_loss: 1.0696 - val_accuracy: 0.4800\n",
      "Epoch 206/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9940 - accuracy: 0.5882 - val_loss: 1.0676 - val_accuracy: 0.4800\n",
      "Epoch 207/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.9923 - accuracy: 0.5882 - val_loss: 1.0656 - val_accuracy: 0.4800\n",
      "Epoch 208/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9903 - accuracy: 0.5882 - val_loss: 1.0641 - val_accuracy: 0.4800\n",
      "Epoch 209/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9886 - accuracy: 0.5882 - val_loss: 1.0624 - val_accuracy: 0.4800\n",
      "Epoch 210/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9867 - accuracy: 0.5882 - val_loss: 1.0605 - val_accuracy: 0.4800\n",
      "Epoch 211/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.9851 - accuracy: 0.5882 - val_loss: 1.0586 - val_accuracy: 0.4800\n",
      "Epoch 212/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9833 - accuracy: 0.5882 - val_loss: 1.0568 - val_accuracy: 0.4800\n",
      "Epoch 213/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9814 - accuracy: 0.5882 - val_loss: 1.0548 - val_accuracy: 0.4800\n",
      "Epoch 214/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.9800 - accuracy: 0.5882 - val_loss: 1.0528 - val_accuracy: 0.4800\n",
      "Epoch 215/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.9780 - accuracy: 0.5882 - val_loss: 1.0513 - val_accuracy: 0.5600\n",
      "Epoch 216/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9762 - accuracy: 0.5882 - val_loss: 1.0498 - val_accuracy: 0.5600\n",
      "Epoch 217/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.9745 - accuracy: 0.6078 - val_loss: 1.0483 - val_accuracy: 0.5600\n",
      "Epoch 218/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9727 - accuracy: 0.6078 - val_loss: 1.0469 - val_accuracy: 0.5600\n",
      "Epoch 219/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9710 - accuracy: 0.6078 - val_loss: 1.0454 - val_accuracy: 0.5600\n",
      "Epoch 220/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9692 - accuracy: 0.6078 - val_loss: 1.0440 - val_accuracy: 0.5600\n",
      "Epoch 221/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9675 - accuracy: 0.6078 - val_loss: 1.0426 - val_accuracy: 0.5600\n",
      "Epoch 222/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.9659 - accuracy: 0.6078 - val_loss: 1.0415 - val_accuracy: 0.5600\n",
      "Epoch 223/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9642 - accuracy: 0.6078 - val_loss: 1.0400 - val_accuracy: 0.5600\n",
      "Epoch 224/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.9624 - accuracy: 0.6078 - val_loss: 1.0388 - val_accuracy: 0.5600\n",
      "Epoch 225/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.9606 - accuracy: 0.6078 - val_loss: 1.0372 - val_accuracy: 0.5600\n",
      "Epoch 226/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9590 - accuracy: 0.6078 - val_loss: 1.0354 - val_accuracy: 0.5600\n",
      "Epoch 227/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9572 - accuracy: 0.6078 - val_loss: 1.0338 - val_accuracy: 0.5600\n",
      "Epoch 228/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9556 - accuracy: 0.6078 - val_loss: 1.0317 - val_accuracy: 0.5600\n",
      "Epoch 229/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9540 - accuracy: 0.6078 - val_loss: 1.0294 - val_accuracy: 0.5600\n",
      "Epoch 230/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.9521 - accuracy: 0.6078 - val_loss: 1.0276 - val_accuracy: 0.5600\n",
      "Epoch 231/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9504 - accuracy: 0.6078 - val_loss: 1.0255 - val_accuracy: 0.5600\n",
      "Epoch 232/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9486 - accuracy: 0.6078 - val_loss: 1.0237 - val_accuracy: 0.6000\n",
      "Epoch 233/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9470 - accuracy: 0.6078 - val_loss: 1.0219 - val_accuracy: 0.6000\n",
      "Epoch 234/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9453 - accuracy: 0.6078 - val_loss: 1.0198 - val_accuracy: 0.6000\n",
      "Epoch 235/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9438 - accuracy: 0.6078 - val_loss: 1.0180 - val_accuracy: 0.6000\n",
      "Epoch 236/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9419 - accuracy: 0.6275 - val_loss: 1.0166 - val_accuracy: 0.6000\n",
      "Epoch 237/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9402 - accuracy: 0.6275 - val_loss: 1.0152 - val_accuracy: 0.6000\n",
      "Epoch 238/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9386 - accuracy: 0.6275 - val_loss: 1.0140 - val_accuracy: 0.6000\n",
      "Epoch 239/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.9368 - accuracy: 0.6275 - val_loss: 1.0132 - val_accuracy: 0.6000\n",
      "Epoch 240/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9352 - accuracy: 0.6275 - val_loss: 1.0124 - val_accuracy: 0.6000\n",
      "Epoch 241/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9336 - accuracy: 0.6275 - val_loss: 1.0116 - val_accuracy: 0.6000\n",
      "Epoch 242/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.9320 - accuracy: 0.6275 - val_loss: 1.0107 - val_accuracy: 0.6000\n",
      "Epoch 243/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9304 - accuracy: 0.6275 - val_loss: 1.0095 - val_accuracy: 0.6000\n",
      "Epoch 244/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.9289 - accuracy: 0.6275 - val_loss: 1.0082 - val_accuracy: 0.6000\n",
      "Epoch 245/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9272 - accuracy: 0.6275 - val_loss: 1.0062 - val_accuracy: 0.6000\n",
      "Epoch 246/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.9255 - accuracy: 0.6275 - val_loss: 1.0044 - val_accuracy: 0.6000\n",
      "Epoch 247/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.9238 - accuracy: 0.6275 - val_loss: 1.0024 - val_accuracy: 0.6000\n",
      "Epoch 248/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9221 - accuracy: 0.6275 - val_loss: 1.0002 - val_accuracy: 0.6000\n",
      "Epoch 249/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.9207 - accuracy: 0.6275 - val_loss: 0.9978 - val_accuracy: 0.6000\n",
      "Epoch 250/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.9190 - accuracy: 0.6275 - val_loss: 0.9960 - val_accuracy: 0.6400\n",
      "Epoch 251/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9173 - accuracy: 0.6275 - val_loss: 0.9944 - val_accuracy: 0.6400\n",
      "Epoch 252/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.9156 - accuracy: 0.6275 - val_loss: 0.9925 - val_accuracy: 0.6400\n",
      "Epoch 253/2000\n",
      "51/51 [==============================] - 0s 941us/sample - loss: 0.9141 - accuracy: 0.6275 - val_loss: 0.9907 - val_accuracy: 0.6400\n",
      "Epoch 254/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9124 - accuracy: 0.6275 - val_loss: 0.9892 - val_accuracy: 0.6400\n",
      "Epoch 255/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9107 - accuracy: 0.6275 - val_loss: 0.9876 - val_accuracy: 0.6400\n",
      "Epoch 256/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9093 - accuracy: 0.6275 - val_loss: 0.9861 - val_accuracy: 0.6400\n",
      "Epoch 257/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.9075 - accuracy: 0.6275 - val_loss: 0.9850 - val_accuracy: 0.6400\n",
      "Epoch 258/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9059 - accuracy: 0.6275 - val_loss: 0.9838 - val_accuracy: 0.6400\n",
      "Epoch 259/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.9043 - accuracy: 0.6275 - val_loss: 0.9824 - val_accuracy: 0.6400\n",
      "Epoch 260/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.9026 - accuracy: 0.6275 - val_loss: 0.9810 - val_accuracy: 0.6400\n",
      "Epoch 261/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.62 - 0s 804us/sample - loss: 0.9010 - accuracy: 0.6275 - val_loss: 0.9793 - val_accuracy: 0.6400\n",
      "Epoch 262/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8993 - accuracy: 0.6275 - val_loss: 0.9778 - val_accuracy: 0.6400\n",
      "Epoch 263/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.8977 - accuracy: 0.6275 - val_loss: 0.9763 - val_accuracy: 0.6400\n",
      "Epoch 264/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8961 - accuracy: 0.6275 - val_loss: 0.9746 - val_accuracy: 0.6400\n",
      "Epoch 265/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8945 - accuracy: 0.6275 - val_loss: 0.9732 - val_accuracy: 0.6400\n",
      "Epoch 266/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8928 - accuracy: 0.6275 - val_loss: 0.9717 - val_accuracy: 0.6400\n",
      "Epoch 267/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8912 - accuracy: 0.6275 - val_loss: 0.9699 - val_accuracy: 0.6400\n",
      "Epoch 268/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8897 - accuracy: 0.6275 - val_loss: 0.9682 - val_accuracy: 0.6400\n",
      "Epoch 269/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8880 - accuracy: 0.6275 - val_loss: 0.9668 - val_accuracy: 0.6400\n",
      "Epoch 270/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.8863 - accuracy: 0.6471 - val_loss: 0.9658 - val_accuracy: 0.6400\n",
      "Epoch 271/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.8846 - accuracy: 0.6471 - val_loss: 0.9648 - val_accuracy: 0.6400\n",
      "Epoch 272/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8830 - accuracy: 0.6471 - val_loss: 0.9639 - val_accuracy: 0.6400\n",
      "Epoch 273/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8816 - accuracy: 0.6275 - val_loss: 0.9629 - val_accuracy: 0.6400\n",
      "Epoch 274/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8800 - accuracy: 0.6471 - val_loss: 0.9618 - val_accuracy: 0.6400\n",
      "Epoch 275/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8782 - accuracy: 0.6471 - val_loss: 0.9600 - val_accuracy: 0.6400\n",
      "Epoch 276/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8766 - accuracy: 0.6471 - val_loss: 0.9582 - val_accuracy: 0.6400\n",
      "Epoch 277/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.8750 - accuracy: 0.6471 - val_loss: 0.9565 - val_accuracy: 0.6400\n",
      "Epoch 278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 824us/sample - loss: 0.8733 - accuracy: 0.6471 - val_loss: 0.9550 - val_accuracy: 0.6400\n",
      "Epoch 279/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8719 - accuracy: 0.6471 - val_loss: 0.9533 - val_accuracy: 0.6400\n",
      "Epoch 280/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8706 - accuracy: 0.6471 - val_loss: 0.9519 - val_accuracy: 0.6400\n",
      "Epoch 281/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.8687 - accuracy: 0.6471 - val_loss: 0.9512 - val_accuracy: 0.6400\n",
      "Epoch 282/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.8671 - accuracy: 0.6471 - val_loss: 0.9502 - val_accuracy: 0.6400\n",
      "Epoch 283/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8656 - accuracy: 0.6471 - val_loss: 0.9488 - val_accuracy: 0.6400\n",
      "Epoch 284/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8640 - accuracy: 0.6471 - val_loss: 0.9476 - val_accuracy: 0.6400\n",
      "Epoch 285/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.8624 - accuracy: 0.6471 - val_loss: 0.9461 - val_accuracy: 0.6400\n",
      "Epoch 286/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.8608 - accuracy: 0.6471 - val_loss: 0.9450 - val_accuracy: 0.6400\n",
      "Epoch 287/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.8592 - accuracy: 0.6471 - val_loss: 0.9439 - val_accuracy: 0.6400\n",
      "Epoch 288/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 0.8579 - accuracy: 0.6471 - val_loss: 0.9429 - val_accuracy: 0.6400\n",
      "Epoch 289/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.8563 - accuracy: 0.6471 - val_loss: 0.9412 - val_accuracy: 0.6400\n",
      "Epoch 290/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.8547 - accuracy: 0.6471 - val_loss: 0.9397 - val_accuracy: 0.6400\n",
      "Epoch 291/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8531 - accuracy: 0.6471 - val_loss: 0.9385 - val_accuracy: 0.6400\n",
      "Epoch 292/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8516 - accuracy: 0.6471 - val_loss: 0.9373 - val_accuracy: 0.6400\n",
      "Epoch 293/2000\n",
      "51/51 [==============================] - 0s 843us/sample - loss: 0.8500 - accuracy: 0.6471 - val_loss: 0.9356 - val_accuracy: 0.6400\n",
      "Epoch 294/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8485 - accuracy: 0.6471 - val_loss: 0.9341 - val_accuracy: 0.6400\n",
      "Epoch 295/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8470 - accuracy: 0.6471 - val_loss: 0.9322 - val_accuracy: 0.6400\n",
      "Epoch 296/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8454 - accuracy: 0.6471 - val_loss: 0.9304 - val_accuracy: 0.6400\n",
      "Epoch 297/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8440 - accuracy: 0.6471 - val_loss: 0.9287 - val_accuracy: 0.6400\n",
      "Epoch 298/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.8424 - accuracy: 0.6471 - val_loss: 0.9273 - val_accuracy: 0.6400\n",
      "Epoch 299/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8409 - accuracy: 0.6471 - val_loss: 0.9262 - val_accuracy: 0.6400\n",
      "Epoch 300/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.8395 - accuracy: 0.6471 - val_loss: 0.9252 - val_accuracy: 0.6400\n",
      "Epoch 301/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8379 - accuracy: 0.6471 - val_loss: 0.9238 - val_accuracy: 0.6400\n",
      "Epoch 302/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8364 - accuracy: 0.6471 - val_loss: 0.9223 - val_accuracy: 0.6400\n",
      "Epoch 303/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.8351 - accuracy: 0.6471 - val_loss: 0.9206 - val_accuracy: 0.6800\n",
      "Epoch 304/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8338 - accuracy: 0.6471 - val_loss: 0.9193 - val_accuracy: 0.6800\n",
      "Epoch 305/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8321 - accuracy: 0.6471 - val_loss: 0.9176 - val_accuracy: 0.6800\n",
      "Epoch 306/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8306 - accuracy: 0.6667 - val_loss: 0.9157 - val_accuracy: 0.6800\n",
      "Epoch 307/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8292 - accuracy: 0.6863 - val_loss: 0.9141 - val_accuracy: 0.6800\n",
      "Epoch 308/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8278 - accuracy: 0.6863 - val_loss: 0.9127 - val_accuracy: 0.6800\n",
      "Epoch 309/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8263 - accuracy: 0.6863 - val_loss: 0.9117 - val_accuracy: 0.6800\n",
      "Epoch 310/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.8249 - accuracy: 0.6863 - val_loss: 0.9110 - val_accuracy: 0.6800\n",
      "Epoch 311/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.8234 - accuracy: 0.6863 - val_loss: 0.9098 - val_accuracy: 0.6800\n",
      "Epoch 312/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.8219 - accuracy: 0.6863 - val_loss: 0.9089 - val_accuracy: 0.6800\n",
      "Epoch 313/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8205 - accuracy: 0.6863 - val_loss: 0.9083 - val_accuracy: 0.6800\n",
      "Epoch 314/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8190 - accuracy: 0.6863 - val_loss: 0.9072 - val_accuracy: 0.6800\n",
      "Epoch 315/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8175 - accuracy: 0.6863 - val_loss: 0.9061 - val_accuracy: 0.6800\n",
      "Epoch 316/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.8161 - accuracy: 0.6863 - val_loss: 0.9050 - val_accuracy: 0.6800\n",
      "Epoch 317/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.8147 - accuracy: 0.6863 - val_loss: 0.9037 - val_accuracy: 0.6800\n",
      "Epoch 318/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.8134 - accuracy: 0.6863 - val_loss: 0.9021 - val_accuracy: 0.6800\n",
      "Epoch 319/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.8120 - accuracy: 0.7059 - val_loss: 0.9002 - val_accuracy: 0.6800\n",
      "Epoch 320/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.8105 - accuracy: 0.7059 - val_loss: 0.8989 - val_accuracy: 0.6800\n",
      "Epoch 321/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.8090 - accuracy: 0.7059 - val_loss: 0.8978 - val_accuracy: 0.6800\n",
      "Epoch 322/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.8076 - accuracy: 0.7059 - val_loss: 0.8968 - val_accuracy: 0.6800\n",
      "Epoch 323/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.8062 - accuracy: 0.7059 - val_loss: 0.8956 - val_accuracy: 0.6800\n",
      "Epoch 324/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.8048 - accuracy: 0.7059 - val_loss: 0.8942 - val_accuracy: 0.6800\n",
      "Epoch 325/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.8034 - accuracy: 0.7059 - val_loss: 0.8928 - val_accuracy: 0.6800\n",
      "Epoch 326/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.8019 - accuracy: 0.7059 - val_loss: 0.8912 - val_accuracy: 0.6800\n",
      "Epoch 327/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.8006 - accuracy: 0.7059 - val_loss: 0.8895 - val_accuracy: 0.6800\n",
      "Epoch 328/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.7992 - accuracy: 0.7059 - val_loss: 0.8880 - val_accuracy: 0.6800\n",
      "Epoch 329/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7979 - accuracy: 0.7059 - val_loss: 0.8865 - val_accuracy: 0.6800\n",
      "Epoch 330/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7966 - accuracy: 0.7059 - val_loss: 0.8852 - val_accuracy: 0.6800\n",
      "Epoch 331/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7952 - accuracy: 0.7059 - val_loss: 0.8834 - val_accuracy: 0.6800\n",
      "Epoch 332/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7938 - accuracy: 0.7059 - val_loss: 0.8819 - val_accuracy: 0.6800\n",
      "Epoch 333/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7926 - accuracy: 0.7059 - val_loss: 0.8807 - val_accuracy: 0.6800\n",
      "Epoch 334/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.7911 - accuracy: 0.7059 - val_loss: 0.8800 - val_accuracy: 0.6800\n",
      "Epoch 335/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7897 - accuracy: 0.7059 - val_loss: 0.8796 - val_accuracy: 0.6800\n",
      "Epoch 336/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.7885 - accuracy: 0.7059 - val_loss: 0.8791 - val_accuracy: 0.6800\n",
      "Epoch 337/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7869 - accuracy: 0.7059 - val_loss: 0.8782 - val_accuracy: 0.6800\n",
      "Epoch 338/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.7855 - accuracy: 0.7059 - val_loss: 0.8772 - val_accuracy: 0.6800\n",
      "Epoch 339/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7843 - accuracy: 0.7059 - val_loss: 0.8765 - val_accuracy: 0.6800\n",
      "Epoch 340/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.7829 - accuracy: 0.7059 - val_loss: 0.8761 - val_accuracy: 0.6800\n",
      "Epoch 341/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7818 - accuracy: 0.7059 - val_loss: 0.8762 - val_accuracy: 0.6800\n",
      "Epoch 342/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.7804 - accuracy: 0.7059 - val_loss: 0.8756 - val_accuracy: 0.6800\n",
      "Epoch 343/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.7791 - accuracy: 0.7059 - val_loss: 0.8746 - val_accuracy: 0.6800\n",
      "Epoch 344/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7778 - accuracy: 0.7059 - val_loss: 0.8729 - val_accuracy: 0.6800\n",
      "Epoch 345/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.7765 - accuracy: 0.7059 - val_loss: 0.8716 - val_accuracy: 0.6800\n",
      "Epoch 346/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.7751 - accuracy: 0.7059 - val_loss: 0.8704 - val_accuracy: 0.6800\n",
      "Epoch 347/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7741 - accuracy: 0.7059 - val_loss: 0.8693 - val_accuracy: 0.6800\n",
      "Epoch 348/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7726 - accuracy: 0.7059 - val_loss: 0.8675 - val_accuracy: 0.7200\n",
      "Epoch 349/2000\n",
      "51/51 [==============================] - 0s 843us/sample - loss: 0.7713 - accuracy: 0.7059 - val_loss: 0.8660 - val_accuracy: 0.7200\n",
      "Epoch 350/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.7700 - accuracy: 0.7059 - val_loss: 0.8640 - val_accuracy: 0.7200\n",
      "Epoch 351/2000\n",
      "51/51 [==============================] - 0s 825us/sample - loss: 0.7687 - accuracy: 0.7059 - val_loss: 0.8622 - val_accuracy: 0.7200\n",
      "Epoch 352/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.7675 - accuracy: 0.7059 - val_loss: 0.8604 - val_accuracy: 0.7200\n",
      "Epoch 353/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7662 - accuracy: 0.7059 - val_loss: 0.8587 - val_accuracy: 0.7200\n",
      "Epoch 354/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.7651 - accuracy: 0.7059 - val_loss: 0.8571 - val_accuracy: 0.7200\n",
      "Epoch 355/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7638 - accuracy: 0.7059 - val_loss: 0.8560 - val_accuracy: 0.7200\n",
      "Epoch 356/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7627 - accuracy: 0.7059 - val_loss: 0.8550 - val_accuracy: 0.7200\n",
      "Epoch 357/2000\n",
      "51/51 [==============================] - 0s 825us/sample - loss: 0.7613 - accuracy: 0.7059 - val_loss: 0.8538 - val_accuracy: 0.7200\n",
      "Epoch 358/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7601 - accuracy: 0.7059 - val_loss: 0.8526 - val_accuracy: 0.7200\n",
      "Epoch 359/2000\n",
      "51/51 [==============================] - 0s 882us/sample - loss: 0.7591 - accuracy: 0.7059 - val_loss: 0.8513 - val_accuracy: 0.7200\n",
      "Epoch 360/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7577 - accuracy: 0.7059 - val_loss: 0.8506 - val_accuracy: 0.7200\n",
      "Epoch 361/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.7564 - accuracy: 0.7059 - val_loss: 0.8499 - val_accuracy: 0.7200\n",
      "Epoch 362/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.7554 - accuracy: 0.7059 - val_loss: 0.8495 - val_accuracy: 0.7200\n",
      "Epoch 363/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7540 - accuracy: 0.7059 - val_loss: 0.8487 - val_accuracy: 0.7200\n",
      "Epoch 364/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7527 - accuracy: 0.7059 - val_loss: 0.8475 - val_accuracy: 0.7200\n",
      "Epoch 365/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7515 - accuracy: 0.7059 - val_loss: 0.8463 - val_accuracy: 0.7200\n",
      "Epoch 366/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.7504 - accuracy: 0.7255 - val_loss: 0.8450 - val_accuracy: 0.7200\n",
      "Epoch 367/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7492 - accuracy: 0.7255 - val_loss: 0.8440 - val_accuracy: 0.7200\n",
      "Epoch 368/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7481 - accuracy: 0.7255 - val_loss: 0.8432 - val_accuracy: 0.7200\n",
      "Epoch 369/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7468 - accuracy: 0.7255 - val_loss: 0.8426 - val_accuracy: 0.7200\n",
      "Epoch 370/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7459 - accuracy: 0.7255 - val_loss: 0.8423 - val_accuracy: 0.7200\n",
      "Epoch 371/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7445 - accuracy: 0.7255 - val_loss: 0.8414 - val_accuracy: 0.7200\n",
      "Epoch 372/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.7432 - accuracy: 0.7255 - val_loss: 0.8413 - val_accuracy: 0.7200\n",
      "Epoch 373/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7420 - accuracy: 0.7059 - val_loss: 0.8409 - val_accuracy: 0.7200\n",
      "Epoch 374/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7409 - accuracy: 0.7059 - val_loss: 0.8405 - val_accuracy: 0.7200\n",
      "Epoch 375/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7397 - accuracy: 0.7059 - val_loss: 0.8397 - val_accuracy: 0.7200\n",
      "Epoch 376/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.7389 - accuracy: 0.7059 - val_loss: 0.8386 - val_accuracy: 0.7200\n",
      "Epoch 377/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.7375 - accuracy: 0.7059 - val_loss: 0.8368 - val_accuracy: 0.7200\n",
      "Epoch 378/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7361 - accuracy: 0.7255 - val_loss: 0.8356 - val_accuracy: 0.7200\n",
      "Epoch 379/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7349 - accuracy: 0.7255 - val_loss: 0.8346 - val_accuracy: 0.7200\n",
      "Epoch 380/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7338 - accuracy: 0.7255 - val_loss: 0.8334 - val_accuracy: 0.7200\n",
      "Epoch 381/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.7327 - accuracy: 0.7255 - val_loss: 0.8325 - val_accuracy: 0.7200\n",
      "Epoch 382/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.7316 - accuracy: 0.7255 - val_loss: 0.8319 - val_accuracy: 0.7200\n",
      "Epoch 383/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7305 - accuracy: 0.7255 - val_loss: 0.8310 - val_accuracy: 0.7200\n",
      "Epoch 384/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.7293 - accuracy: 0.7255 - val_loss: 0.8299 - val_accuracy: 0.7200\n",
      "Epoch 385/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7281 - accuracy: 0.7255 - val_loss: 0.8288 - val_accuracy: 0.7200\n",
      "Epoch 386/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7270 - accuracy: 0.7255 - val_loss: 0.8273 - val_accuracy: 0.7200\n",
      "Epoch 387/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.7261 - accuracy: 0.7255 - val_loss: 0.8261 - val_accuracy: 0.7200\n",
      "Epoch 388/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 942us/sample - loss: 0.7251 - accuracy: 0.7255 - val_loss: 0.8259 - val_accuracy: 0.7200\n",
      "Epoch 389/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7238 - accuracy: 0.7255 - val_loss: 0.8249 - val_accuracy: 0.7200\n",
      "Epoch 390/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.7225 - accuracy: 0.7255 - val_loss: 0.8248 - val_accuracy: 0.7200\n",
      "Epoch 391/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7214 - accuracy: 0.7255 - val_loss: 0.8244 - val_accuracy: 0.7200\n",
      "Epoch 392/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7203 - accuracy: 0.7255 - val_loss: 0.8244 - val_accuracy: 0.7200\n",
      "Epoch 393/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.7191 - accuracy: 0.7255 - val_loss: 0.8240 - val_accuracy: 0.7200\n",
      "Epoch 394/2000\n",
      "51/51 [==============================] - 0s 982us/sample - loss: 0.7183 - accuracy: 0.7255 - val_loss: 0.8237 - val_accuracy: 0.7200\n",
      "Epoch 395/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 0.7170 - accuracy: 0.7255 - val_loss: 0.8232 - val_accuracy: 0.7200\n",
      "Epoch 396/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.7161 - accuracy: 0.7255 - val_loss: 0.8227 - val_accuracy: 0.7200\n",
      "Epoch 397/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7150 - accuracy: 0.7255 - val_loss: 0.8216 - val_accuracy: 0.7200\n",
      "Epoch 398/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7139 - accuracy: 0.7255 - val_loss: 0.8208 - val_accuracy: 0.7200\n",
      "Epoch 399/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.7128 - accuracy: 0.7255 - val_loss: 0.8202 - val_accuracy: 0.7200\n",
      "Epoch 400/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.7117 - accuracy: 0.7255 - val_loss: 0.8192 - val_accuracy: 0.7200\n",
      "Epoch 401/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.7106 - accuracy: 0.7255 - val_loss: 0.8185 - val_accuracy: 0.7200\n",
      "Epoch 402/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.7096 - accuracy: 0.7255 - val_loss: 0.8177 - val_accuracy: 0.7200\n",
      "Epoch 403/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7085 - accuracy: 0.7255 - val_loss: 0.8170 - val_accuracy: 0.7200\n",
      "Epoch 404/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.7075 - accuracy: 0.7255 - val_loss: 0.8158 - val_accuracy: 0.7200\n",
      "Epoch 405/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7064 - accuracy: 0.7255 - val_loss: 0.8150 - val_accuracy: 0.7200\n",
      "Epoch 406/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.7053 - accuracy: 0.7255 - val_loss: 0.8144 - val_accuracy: 0.7200\n",
      "Epoch 407/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.7043 - accuracy: 0.7255 - val_loss: 0.8137 - val_accuracy: 0.7200\n",
      "Epoch 408/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.7032 - accuracy: 0.7255 - val_loss: 0.8126 - val_accuracy: 0.7200\n",
      "Epoch 409/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.7021 - accuracy: 0.7255 - val_loss: 0.8112 - val_accuracy: 0.7200\n",
      "Epoch 410/2000\n",
      "51/51 [==============================] - 0s 843us/sample - loss: 0.7009 - accuracy: 0.7255 - val_loss: 0.8092 - val_accuracy: 0.7200\n",
      "Epoch 411/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6998 - accuracy: 0.7255 - val_loss: 0.8074 - val_accuracy: 0.7200\n",
      "Epoch 412/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.6988 - accuracy: 0.7255 - val_loss: 0.8058 - val_accuracy: 0.7200\n",
      "Epoch 413/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6978 - accuracy: 0.7255 - val_loss: 0.8043 - val_accuracy: 0.7200\n",
      "Epoch 414/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6967 - accuracy: 0.7255 - val_loss: 0.8025 - val_accuracy: 0.7200\n",
      "Epoch 415/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6958 - accuracy: 0.7255 - val_loss: 0.8009 - val_accuracy: 0.7200\n",
      "Epoch 416/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6952 - accuracy: 0.7255 - val_loss: 0.7997 - val_accuracy: 0.7200\n",
      "Epoch 417/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6938 - accuracy: 0.7255 - val_loss: 0.7989 - val_accuracy: 0.7200\n",
      "Epoch 418/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6931 - accuracy: 0.7255 - val_loss: 0.7983 - val_accuracy: 0.7200\n",
      "Epoch 419/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6917 - accuracy: 0.7255 - val_loss: 0.7972 - val_accuracy: 0.7200\n",
      "Epoch 420/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6908 - accuracy: 0.7255 - val_loss: 0.7964 - val_accuracy: 0.7200\n",
      "Epoch 421/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.6899 - accuracy: 0.7255 - val_loss: 0.7961 - val_accuracy: 0.7200\n",
      "Epoch 422/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6888 - accuracy: 0.7255 - val_loss: 0.7957 - val_accuracy: 0.7200\n",
      "Epoch 423/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6876 - accuracy: 0.7255 - val_loss: 0.7951 - val_accuracy: 0.7200\n",
      "Epoch 424/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6865 - accuracy: 0.7255 - val_loss: 0.7945 - val_accuracy: 0.7200\n",
      "Epoch 425/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6854 - accuracy: 0.7255 - val_loss: 0.7941 - val_accuracy: 0.7200\n",
      "Epoch 426/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6845 - accuracy: 0.7255 - val_loss: 0.7938 - val_accuracy: 0.7200\n",
      "Epoch 427/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6834 - accuracy: 0.7255 - val_loss: 0.7935 - val_accuracy: 0.7200\n",
      "Epoch 428/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6826 - accuracy: 0.7255 - val_loss: 0.7934 - val_accuracy: 0.7200\n",
      "Epoch 429/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6813 - accuracy: 0.7255 - val_loss: 0.7925 - val_accuracy: 0.7200\n",
      "Epoch 430/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6804 - accuracy: 0.7255 - val_loss: 0.7917 - val_accuracy: 0.7200\n",
      "Epoch 431/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6793 - accuracy: 0.7255 - val_loss: 0.7914 - val_accuracy: 0.7200\n",
      "Epoch 432/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6782 - accuracy: 0.7255 - val_loss: 0.7907 - val_accuracy: 0.7200\n",
      "Epoch 433/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6773 - accuracy: 0.7255 - val_loss: 0.7902 - val_accuracy: 0.7200\n",
      "Epoch 434/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.6766 - accuracy: 0.7255 - val_loss: 0.7906 - val_accuracy: 0.7200\n",
      "Epoch 435/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6752 - accuracy: 0.7255 - val_loss: 0.7899 - val_accuracy: 0.7200\n",
      "Epoch 436/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.6741 - accuracy: 0.7255 - val_loss: 0.7891 - val_accuracy: 0.7200\n",
      "Epoch 437/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6737 - accuracy: 0.7255 - val_loss: 0.7882 - val_accuracy: 0.7200\n",
      "Epoch 438/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6723 - accuracy: 0.7255 - val_loss: 0.7867 - val_accuracy: 0.7200\n",
      "Epoch 439/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6713 - accuracy: 0.7255 - val_loss: 0.7851 - val_accuracy: 0.7200\n",
      "Epoch 440/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6702 - accuracy: 0.7255 - val_loss: 0.7842 - val_accuracy: 0.7200\n",
      "Epoch 441/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.6693 - accuracy: 0.7255 - val_loss: 0.7830 - val_accuracy: 0.7200\n",
      "Epoch 442/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.6683 - accuracy: 0.7255 - val_loss: 0.7820 - val_accuracy: 0.7200\n",
      "Epoch 443/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 864us/sample - loss: 0.6672 - accuracy: 0.7255 - val_loss: 0.7813 - val_accuracy: 0.7200\n",
      "Epoch 444/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6662 - accuracy: 0.7255 - val_loss: 0.7809 - val_accuracy: 0.7200\n",
      "Epoch 445/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6653 - accuracy: 0.7255 - val_loss: 0.7803 - val_accuracy: 0.7200\n",
      "Epoch 446/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6642 - accuracy: 0.7255 - val_loss: 0.7798 - val_accuracy: 0.7200\n",
      "Epoch 447/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.6632 - accuracy: 0.7255 - val_loss: 0.7800 - val_accuracy: 0.7200\n",
      "Epoch 448/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6621 - accuracy: 0.7255 - val_loss: 0.7798 - val_accuracy: 0.7200\n",
      "Epoch 449/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6611 - accuracy: 0.7255 - val_loss: 0.7794 - val_accuracy: 0.7200\n",
      "Epoch 450/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.6603 - accuracy: 0.7255 - val_loss: 0.7790 - val_accuracy: 0.7200\n",
      "Epoch 451/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6590 - accuracy: 0.7255 - val_loss: 0.7778 - val_accuracy: 0.7200\n",
      "Epoch 452/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.6580 - accuracy: 0.7255 - val_loss: 0.7764 - val_accuracy: 0.7200\n",
      "Epoch 453/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6570 - accuracy: 0.7255 - val_loss: 0.7752 - val_accuracy: 0.7200\n",
      "Epoch 454/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.6561 - accuracy: 0.7255 - val_loss: 0.7746 - val_accuracy: 0.7200\n",
      "Epoch 455/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6550 - accuracy: 0.7255 - val_loss: 0.7735 - val_accuracy: 0.7200\n",
      "Epoch 456/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6539 - accuracy: 0.7255 - val_loss: 0.7721 - val_accuracy: 0.7200\n",
      "Epoch 457/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.6528 - accuracy: 0.7255 - val_loss: 0.7708 - val_accuracy: 0.7200\n",
      "Epoch 458/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6523 - accuracy: 0.7255 - val_loss: 0.7700 - val_accuracy: 0.7200\n",
      "Epoch 459/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.6509 - accuracy: 0.7255 - val_loss: 0.7684 - val_accuracy: 0.7200\n",
      "Epoch 460/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6500 - accuracy: 0.7255 - val_loss: 0.7668 - val_accuracy: 0.7200\n",
      "Epoch 461/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6492 - accuracy: 0.7255 - val_loss: 0.7658 - val_accuracy: 0.7200\n",
      "Epoch 462/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6486 - accuracy: 0.7255 - val_loss: 0.7648 - val_accuracy: 0.7200\n",
      "Epoch 463/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6474 - accuracy: 0.7255 - val_loss: 0.7647 - val_accuracy: 0.7200\n",
      "Epoch 464/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6463 - accuracy: 0.7255 - val_loss: 0.7646 - val_accuracy: 0.7200\n",
      "Epoch 465/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6452 - accuracy: 0.7255 - val_loss: 0.7650 - val_accuracy: 0.7200\n",
      "Epoch 466/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.6444 - accuracy: 0.7255 - val_loss: 0.7659 - val_accuracy: 0.7200\n",
      "Epoch 467/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6433 - accuracy: 0.7255 - val_loss: 0.7663 - val_accuracy: 0.7200\n",
      "Epoch 468/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6421 - accuracy: 0.7255 - val_loss: 0.7662 - val_accuracy: 0.7200\n",
      "Epoch 469/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6410 - accuracy: 0.7255 - val_loss: 0.7658 - val_accuracy: 0.7200\n",
      "Epoch 470/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6403 - accuracy: 0.7255 - val_loss: 0.7658 - val_accuracy: 0.7200\n",
      "Epoch 471/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6391 - accuracy: 0.7255 - val_loss: 0.7652 - val_accuracy: 0.7200\n",
      "Epoch 472/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6381 - accuracy: 0.7255 - val_loss: 0.7650 - val_accuracy: 0.7200\n",
      "Epoch 473/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6375 - accuracy: 0.7255 - val_loss: 0.7652 - val_accuracy: 0.7200\n",
      "Epoch 474/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6363 - accuracy: 0.7255 - val_loss: 0.7645 - val_accuracy: 0.7200\n",
      "Epoch 475/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6355 - accuracy: 0.7255 - val_loss: 0.7636 - val_accuracy: 0.7200\n",
      "Epoch 476/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6345 - accuracy: 0.7255 - val_loss: 0.7617 - val_accuracy: 0.7200\n",
      "Epoch 477/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6333 - accuracy: 0.7255 - val_loss: 0.7604 - val_accuracy: 0.7200\n",
      "Epoch 478/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6329 - accuracy: 0.7255 - val_loss: 0.7590 - val_accuracy: 0.7200\n",
      "Epoch 479/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6314 - accuracy: 0.7255 - val_loss: 0.7585 - val_accuracy: 0.7200\n",
      "Epoch 480/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.6305 - accuracy: 0.7255 - val_loss: 0.7580 - val_accuracy: 0.7200\n",
      "Epoch 481/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.6296 - accuracy: 0.7255 - val_loss: 0.7575 - val_accuracy: 0.7200\n",
      "Epoch 482/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6285 - accuracy: 0.7255 - val_loss: 0.7574 - val_accuracy: 0.7200\n",
      "Epoch 483/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6279 - accuracy: 0.7255 - val_loss: 0.7574 - val_accuracy: 0.7200\n",
      "Epoch 484/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6268 - accuracy: 0.7255 - val_loss: 0.7569 - val_accuracy: 0.7200\n",
      "Epoch 485/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6258 - accuracy: 0.7255 - val_loss: 0.7558 - val_accuracy: 0.7200\n",
      "Epoch 486/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.6249 - accuracy: 0.7451 - val_loss: 0.7547 - val_accuracy: 0.7200\n",
      "Epoch 487/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6239 - accuracy: 0.7451 - val_loss: 0.7539 - val_accuracy: 0.7200\n",
      "Epoch 488/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6230 - accuracy: 0.7451 - val_loss: 0.7535 - val_accuracy: 0.7200\n",
      "Epoch 489/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.6220 - accuracy: 0.7647 - val_loss: 0.7529 - val_accuracy: 0.7200\n",
      "Epoch 490/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6210 - accuracy: 0.7647 - val_loss: 0.7526 - val_accuracy: 0.7200\n",
      "Epoch 491/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6201 - accuracy: 0.7647 - val_loss: 0.7524 - val_accuracy: 0.7200\n",
      "Epoch 492/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.6192 - accuracy: 0.7647 - val_loss: 0.7523 - val_accuracy: 0.7200\n",
      "Epoch 493/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.6183 - accuracy: 0.7647 - val_loss: 0.7521 - val_accuracy: 0.7200\n",
      "Epoch 494/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6174 - accuracy: 0.7647 - val_loss: 0.7513 - val_accuracy: 0.7200\n",
      "Epoch 495/2000\n",
      "51/51 [==============================] - 0s 882us/sample - loss: 0.6168 - accuracy: 0.7647 - val_loss: 0.7501 - val_accuracy: 0.7200\n",
      "Epoch 496/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6157 - accuracy: 0.7647 - val_loss: 0.7494 - val_accuracy: 0.7200\n",
      "Epoch 497/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6144 - accuracy: 0.7647 - val_loss: 0.7494 - val_accuracy: 0.7200\n",
      "Epoch 498/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6137 - accuracy: 0.7647 - val_loss: 0.7495 - val_accuracy: 0.7200\n",
      "Epoch 499/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6126 - accuracy: 0.7647 - val_loss: 0.7490 - val_accuracy: 0.7200\n",
      "Epoch 500/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6118 - accuracy: 0.7647 - val_loss: 0.7485 - val_accuracy: 0.7200\n",
      "Epoch 501/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6108 - accuracy: 0.7647 - val_loss: 0.7475 - val_accuracy: 0.7200\n",
      "Epoch 502/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.6099 - accuracy: 0.7647 - val_loss: 0.7463 - val_accuracy: 0.7200\n",
      "Epoch 503/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.6089 - accuracy: 0.7647 - val_loss: 0.7453 - val_accuracy: 0.7200\n",
      "Epoch 504/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.6080 - accuracy: 0.7647 - val_loss: 0.7447 - val_accuracy: 0.7200\n",
      "Epoch 505/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.6071 - accuracy: 0.7647 - val_loss: 0.7440 - val_accuracy: 0.7200\n",
      "Epoch 506/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.6063 - accuracy: 0.7647 - val_loss: 0.7435 - val_accuracy: 0.7200\n",
      "Epoch 507/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.6052 - accuracy: 0.7647 - val_loss: 0.7426 - val_accuracy: 0.7200\n",
      "Epoch 508/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.6044 - accuracy: 0.7843 - val_loss: 0.7417 - val_accuracy: 0.7200\n",
      "Epoch 509/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.6036 - accuracy: 0.7843 - val_loss: 0.7409 - val_accuracy: 0.7200\n",
      "Epoch 510/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.6028 - accuracy: 0.7843 - val_loss: 0.7404 - val_accuracy: 0.7200\n",
      "Epoch 511/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6021 - accuracy: 0.7843 - val_loss: 0.7402 - val_accuracy: 0.7200\n",
      "Epoch 512/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.6012 - accuracy: 0.7843 - val_loss: 0.7396 - val_accuracy: 0.7200\n",
      "Epoch 513/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.6003 - accuracy: 0.7843 - val_loss: 0.7395 - val_accuracy: 0.7200\n",
      "Epoch 514/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5995 - accuracy: 0.7843 - val_loss: 0.7393 - val_accuracy: 0.7200\n",
      "Epoch 515/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5985 - accuracy: 0.7843 - val_loss: 0.7385 - val_accuracy: 0.7200\n",
      "Epoch 516/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5975 - accuracy: 0.7843 - val_loss: 0.7370 - val_accuracy: 0.7600\n",
      "Epoch 517/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5967 - accuracy: 0.8039 - val_loss: 0.7356 - val_accuracy: 0.7600\n",
      "Epoch 518/2000\n",
      "51/51 [==============================] - 0s 982us/sample - loss: 0.5959 - accuracy: 0.8039 - val_loss: 0.7347 - val_accuracy: 0.7600\n",
      "Epoch 519/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5950 - accuracy: 0.8039 - val_loss: 0.7340 - val_accuracy: 0.7600\n",
      "Epoch 520/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5940 - accuracy: 0.8039 - val_loss: 0.7329 - val_accuracy: 0.7600\n",
      "Epoch 521/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.5932 - accuracy: 0.8235 - val_loss: 0.7322 - val_accuracy: 0.7600\n",
      "Epoch 522/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5924 - accuracy: 0.8235 - val_loss: 0.7318 - val_accuracy: 0.7600\n",
      "Epoch 523/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5913 - accuracy: 0.8235 - val_loss: 0.7313 - val_accuracy: 0.7600\n",
      "Epoch 524/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5906 - accuracy: 0.8235 - val_loss: 0.7309 - val_accuracy: 0.7600\n",
      "Epoch 525/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5895 - accuracy: 0.8431 - val_loss: 0.7313 - val_accuracy: 0.7600\n",
      "Epoch 526/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5885 - accuracy: 0.8431 - val_loss: 0.7314 - val_accuracy: 0.7600\n",
      "Epoch 527/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.5877 - accuracy: 0.8431 - val_loss: 0.7317 - val_accuracy: 0.7600\n",
      "Epoch 528/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5870 - accuracy: 0.8431 - val_loss: 0.7320 - val_accuracy: 0.7600\n",
      "Epoch 529/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5862 - accuracy: 0.8431 - val_loss: 0.7324 - val_accuracy: 0.7600\n",
      "Epoch 530/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.5854 - accuracy: 0.8431 - val_loss: 0.7325 - val_accuracy: 0.7600\n",
      "Epoch 531/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.5847 - accuracy: 0.8235 - val_loss: 0.7327 - val_accuracy: 0.7600\n",
      "Epoch 532/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5840 - accuracy: 0.8235 - val_loss: 0.7323 - val_accuracy: 0.7600\n",
      "Epoch 533/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5831 - accuracy: 0.8235 - val_loss: 0.7310 - val_accuracy: 0.7600\n",
      "Epoch 534/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5821 - accuracy: 0.8235 - val_loss: 0.7295 - val_accuracy: 0.7600\n",
      "Epoch 535/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5813 - accuracy: 0.8431 - val_loss: 0.7275 - val_accuracy: 0.7600\n",
      "Epoch 536/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5800 - accuracy: 0.8431 - val_loss: 0.7258 - val_accuracy: 0.7600\n",
      "Epoch 537/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5794 - accuracy: 0.8431 - val_loss: 0.7240 - val_accuracy: 0.7600\n",
      "Epoch 538/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5787 - accuracy: 0.8431 - val_loss: 0.7227 - val_accuracy: 0.7600\n",
      "Epoch 539/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 0.5775 - accuracy: 0.8431 - val_loss: 0.7221 - val_accuracy: 0.7600\n",
      "Epoch 540/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.5767 - accuracy: 0.8431 - val_loss: 0.7218 - val_accuracy: 0.7600\n",
      "Epoch 541/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5758 - accuracy: 0.8431 - val_loss: 0.7210 - val_accuracy: 0.7600\n",
      "Epoch 542/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5749 - accuracy: 0.8431 - val_loss: 0.7206 - val_accuracy: 0.7600\n",
      "Epoch 543/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5741 - accuracy: 0.8431 - val_loss: 0.7198 - val_accuracy: 0.7600\n",
      "Epoch 544/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5734 - accuracy: 0.8431 - val_loss: 0.7192 - val_accuracy: 0.7600\n",
      "Epoch 545/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5726 - accuracy: 0.8431 - val_loss: 0.7191 - val_accuracy: 0.7600\n",
      "Epoch 546/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5717 - accuracy: 0.8431 - val_loss: 0.7185 - val_accuracy: 0.7600\n",
      "Epoch 547/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5707 - accuracy: 0.8431 - val_loss: 0.7187 - val_accuracy: 0.7600\n",
      "Epoch 548/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5698 - accuracy: 0.8431 - val_loss: 0.7185 - val_accuracy: 0.7600\n",
      "Epoch 549/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5694 - accuracy: 0.8431 - val_loss: 0.7184 - val_accuracy: 0.7600\n",
      "Epoch 550/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5682 - accuracy: 0.8431 - val_loss: 0.7183 - val_accuracy: 0.7600\n",
      "Epoch 551/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5674 - accuracy: 0.8431 - val_loss: 0.7177 - val_accuracy: 0.7600\n",
      "Epoch 552/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5665 - accuracy: 0.8431 - val_loss: 0.7171 - val_accuracy: 0.7600\n",
      "Epoch 553/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5656 - accuracy: 0.8431 - val_loss: 0.7163 - val_accuracy: 0.7600\n",
      "Epoch 554/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5648 - accuracy: 0.8431 - val_loss: 0.7158 - val_accuracy: 0.7600\n",
      "Epoch 555/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.5642 - accuracy: 0.8431 - val_loss: 0.7149 - val_accuracy: 0.7600\n",
      "Epoch 556/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5630 - accuracy: 0.8431 - val_loss: 0.7149 - val_accuracy: 0.7600\n",
      "Epoch 557/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5625 - accuracy: 0.8431 - val_loss: 0.7147 - val_accuracy: 0.7600\n",
      "Epoch 558/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5613 - accuracy: 0.8431 - val_loss: 0.7137 - val_accuracy: 0.7600\n",
      "Epoch 559/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5607 - accuracy: 0.8431 - val_loss: 0.7122 - val_accuracy: 0.7600\n",
      "Epoch 560/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.5599 - accuracy: 0.8431 - val_loss: 0.7111 - val_accuracy: 0.7600\n",
      "Epoch 561/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5590 - accuracy: 0.8431 - val_loss: 0.7108 - val_accuracy: 0.7600\n",
      "Epoch 562/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5582 - accuracy: 0.8431 - val_loss: 0.7106 - val_accuracy: 0.7600\n",
      "Epoch 563/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.5572 - accuracy: 0.8431 - val_loss: 0.7100 - val_accuracy: 0.7600\n",
      "Epoch 564/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5565 - accuracy: 0.8431 - val_loss: 0.7097 - val_accuracy: 0.7600\n",
      "Epoch 565/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.5558 - accuracy: 0.8431 - val_loss: 0.7091 - val_accuracy: 0.7600\n",
      "Epoch 566/2000\n",
      "51/51 [==============================] - 0s 843us/sample - loss: 0.5549 - accuracy: 0.8431 - val_loss: 0.7080 - val_accuracy: 0.7600\n",
      "Epoch 567/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.5540 - accuracy: 0.8431 - val_loss: 0.7076 - val_accuracy: 0.7600\n",
      "Epoch 568/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5532 - accuracy: 0.8431 - val_loss: 0.7073 - val_accuracy: 0.7600\n",
      "Epoch 569/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5524 - accuracy: 0.8431 - val_loss: 0.7075 - val_accuracy: 0.7600\n",
      "Epoch 570/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5516 - accuracy: 0.8431 - val_loss: 0.7076 - val_accuracy: 0.7600\n",
      "Epoch 571/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5508 - accuracy: 0.8431 - val_loss: 0.7074 - val_accuracy: 0.7600\n",
      "Epoch 572/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5500 - accuracy: 0.8431 - val_loss: 0.7067 - val_accuracy: 0.7600\n",
      "Epoch 573/2000\n",
      "51/51 [==============================] - 0s 982us/sample - loss: 0.5492 - accuracy: 0.8431 - val_loss: 0.7061 - val_accuracy: 0.7600\n",
      "Epoch 574/2000\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 0.5484 - accuracy: 0.8431 - val_loss: 0.7056 - val_accuracy: 0.7600\n",
      "Epoch 575/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5476 - accuracy: 0.8431 - val_loss: 0.7054 - val_accuracy: 0.7600\n",
      "Epoch 576/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.5467 - accuracy: 0.8431 - val_loss: 0.7053 - val_accuracy: 0.7600\n",
      "Epoch 577/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.5459 - accuracy: 0.8431 - val_loss: 0.7054 - val_accuracy: 0.7600\n",
      "Epoch 578/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5454 - accuracy: 0.8431 - val_loss: 0.7056 - val_accuracy: 0.7600\n",
      "Epoch 579/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5443 - accuracy: 0.8431 - val_loss: 0.7053 - val_accuracy: 0.7600\n",
      "Epoch 580/2000\n",
      "51/51 [==============================] - 0s 884us/sample - loss: 0.5437 - accuracy: 0.8431 - val_loss: 0.7054 - val_accuracy: 0.7600\n",
      "Epoch 581/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5429 - accuracy: 0.8431 - val_loss: 0.7049 - val_accuracy: 0.7600\n",
      "Epoch 582/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.5422 - accuracy: 0.8431 - val_loss: 0.7045 - val_accuracy: 0.7600\n",
      "Epoch 583/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5414 - accuracy: 0.8431 - val_loss: 0.7032 - val_accuracy: 0.7600\n",
      "Epoch 584/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5405 - accuracy: 0.8431 - val_loss: 0.7026 - val_accuracy: 0.7600\n",
      "Epoch 585/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5397 - accuracy: 0.8431 - val_loss: 0.7019 - val_accuracy: 0.7600\n",
      "Epoch 586/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5392 - accuracy: 0.8431 - val_loss: 0.7006 - val_accuracy: 0.7600\n",
      "Epoch 587/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.5381 - accuracy: 0.8431 - val_loss: 0.7002 - val_accuracy: 0.7600\n",
      "Epoch 588/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.5375 - accuracy: 0.8431 - val_loss: 0.6994 - val_accuracy: 0.7600\n",
      "Epoch 589/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5367 - accuracy: 0.8431 - val_loss: 0.6994 - val_accuracy: 0.7600\n",
      "Epoch 590/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5359 - accuracy: 0.8431 - val_loss: 0.6994 - val_accuracy: 0.7600\n",
      "Epoch 591/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5350 - accuracy: 0.8431 - val_loss: 0.6991 - val_accuracy: 0.7600\n",
      "Epoch 592/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.5341 - accuracy: 0.8431 - val_loss: 0.6995 - val_accuracy: 0.7600\n",
      "Epoch 593/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5334 - accuracy: 0.8431 - val_loss: 0.6999 - val_accuracy: 0.7600\n",
      "Epoch 594/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5327 - accuracy: 0.8431 - val_loss: 0.7005 - val_accuracy: 0.7600\n",
      "Epoch 595/2000\n",
      "51/51 [==============================] - 0s 2ms/sample - loss: 0.5320 - accuracy: 0.8431 - val_loss: 0.7008 - val_accuracy: 0.7600\n",
      "Epoch 596/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5313 - accuracy: 0.8431 - val_loss: 0.7011 - val_accuracy: 0.7600\n",
      "Epoch 597/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5308 - accuracy: 0.8431 - val_loss: 0.7010 - val_accuracy: 0.7600\n",
      "Epoch 598/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5299 - accuracy: 0.8431 - val_loss: 0.7003 - val_accuracy: 0.7600\n",
      "Epoch 599/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.5291 - accuracy: 0.8431 - val_loss: 0.6995 - val_accuracy: 0.7600\n",
      "Epoch 600/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5283 - accuracy: 0.8431 - val_loss: 0.6979 - val_accuracy: 0.7600\n",
      "Epoch 601/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5276 - accuracy: 0.8431 - val_loss: 0.6964 - val_accuracy: 0.7600\n",
      "Epoch 602/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5267 - accuracy: 0.8431 - val_loss: 0.6955 - val_accuracy: 0.7600\n",
      "Epoch 603/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5260 - accuracy: 0.8431 - val_loss: 0.6943 - val_accuracy: 0.7600\n",
      "Epoch 604/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.84 - 0s 942us/sample - loss: 0.5258 - accuracy: 0.8431 - val_loss: 0.6936 - val_accuracy: 0.7600\n",
      "Epoch 605/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5244 - accuracy: 0.8431 - val_loss: 0.6943 - val_accuracy: 0.7600\n",
      "Epoch 606/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.5233 - accuracy: 0.8431 - val_loss: 0.6948 - val_accuracy: 0.7600\n",
      "Epoch 607/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.5231 - accuracy: 0.8431 - val_loss: 0.6953 - val_accuracy: 0.7600\n",
      "Epoch 608/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5228 - accuracy: 0.8431 - val_loss: 0.6956 - val_accuracy: 0.7600\n",
      "Epoch 609/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5218 - accuracy: 0.8431 - val_loss: 0.6953 - val_accuracy: 0.7600\n",
      "Epoch 610/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5210 - accuracy: 0.8431 - val_loss: 0.6942 - val_accuracy: 0.7600\n",
      "Epoch 611/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5201 - accuracy: 0.8431 - val_loss: 0.6922 - val_accuracy: 0.7600\n",
      "Epoch 612/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5191 - accuracy: 0.8431 - val_loss: 0.6903 - val_accuracy: 0.7600\n",
      "Epoch 613/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5184 - accuracy: 0.8431 - val_loss: 0.6883 - val_accuracy: 0.7600\n",
      "Epoch 614/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.5179 - accuracy: 0.8431 - val_loss: 0.6867 - val_accuracy: 0.7600\n",
      "Epoch 615/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5173 - accuracy: 0.8431 - val_loss: 0.6858 - val_accuracy: 0.7600\n",
      "Epoch 616/2000\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 0.5165 - accuracy: 0.8431 - val_loss: 0.6856 - val_accuracy: 0.7600\n",
      "Epoch 617/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.5158 - accuracy: 0.8627 - val_loss: 0.6853 - val_accuracy: 0.7600\n",
      "Epoch 618/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5151 - accuracy: 0.8627 - val_loss: 0.6848 - val_accuracy: 0.7600\n",
      "Epoch 619/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5143 - accuracy: 0.8627 - val_loss: 0.6849 - val_accuracy: 0.7600\n",
      "Epoch 620/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5134 - accuracy: 0.8627 - val_loss: 0.6852 - val_accuracy: 0.7600\n",
      "Epoch 621/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.5126 - accuracy: 0.8627 - val_loss: 0.6855 - val_accuracy: 0.7600\n",
      "Epoch 622/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5121 - accuracy: 0.8627 - val_loss: 0.6857 - val_accuracy: 0.7600\n",
      "Epoch 623/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5113 - accuracy: 0.8627 - val_loss: 0.6855 - val_accuracy: 0.7600\n",
      "Epoch 624/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.5108 - accuracy: 0.8627 - val_loss: 0.6851 - val_accuracy: 0.7600\n",
      "Epoch 625/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5099 - accuracy: 0.8627 - val_loss: 0.6845 - val_accuracy: 0.7600\n",
      "Epoch 626/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.5092 - accuracy: 0.8627 - val_loss: 0.6841 - val_accuracy: 0.7600\n",
      "Epoch 627/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5086 - accuracy: 0.8627 - val_loss: 0.6831 - val_accuracy: 0.7600\n",
      "Epoch 628/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.5078 - accuracy: 0.8627 - val_loss: 0.6824 - val_accuracy: 0.7600\n",
      "Epoch 629/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5071 - accuracy: 0.8627 - val_loss: 0.6819 - val_accuracy: 0.7600\n",
      "Epoch 630/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5065 - accuracy: 0.8627 - val_loss: 0.6821 - val_accuracy: 0.7600\n",
      "Epoch 631/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5056 - accuracy: 0.8627 - val_loss: 0.6816 - val_accuracy: 0.7600\n",
      "Epoch 632/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.5050 - accuracy: 0.8627 - val_loss: 0.6810 - val_accuracy: 0.7600\n",
      "Epoch 633/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5044 - accuracy: 0.8627 - val_loss: 0.6807 - val_accuracy: 0.7600\n",
      "Epoch 634/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5037 - accuracy: 0.8627 - val_loss: 0.6801 - val_accuracy: 0.7600\n",
      "Epoch 635/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.5031 - accuracy: 0.8627 - val_loss: 0.6800 - val_accuracy: 0.7600\n",
      "Epoch 636/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.5028 - accuracy: 0.8627 - val_loss: 0.6805 - val_accuracy: 0.7600\n",
      "Epoch 637/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.5015 - accuracy: 0.8627 - val_loss: 0.6801 - val_accuracy: 0.7600\n",
      "Epoch 638/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.5008 - accuracy: 0.8627 - val_loss: 0.6795 - val_accuracy: 0.7600\n",
      "Epoch 639/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.5002 - accuracy: 0.8627 - val_loss: 0.6787 - val_accuracy: 0.7600\n",
      "Epoch 640/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4994 - accuracy: 0.8627 - val_loss: 0.6781 - val_accuracy: 0.7600\n",
      "Epoch 641/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4988 - accuracy: 0.8627 - val_loss: 0.6775 - val_accuracy: 0.7600\n",
      "Epoch 642/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4983 - accuracy: 0.8627 - val_loss: 0.6769 - val_accuracy: 0.7600\n",
      "Epoch 643/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4975 - accuracy: 0.8627 - val_loss: 0.6761 - val_accuracy: 0.7600\n",
      "Epoch 644/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.4967 - accuracy: 0.8824 - val_loss: 0.6753 - val_accuracy: 0.7600\n",
      "Epoch 645/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4962 - accuracy: 0.8824 - val_loss: 0.6745 - val_accuracy: 0.7600\n",
      "Epoch 646/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4956 - accuracy: 0.8627 - val_loss: 0.6747 - val_accuracy: 0.7600\n",
      "Epoch 647/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4950 - accuracy: 0.8627 - val_loss: 0.6742 - val_accuracy: 0.7600\n",
      "Epoch 648/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.4940 - accuracy: 0.8824 - val_loss: 0.6734 - val_accuracy: 0.7600\n",
      "Epoch 649/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4933 - accuracy: 0.8824 - val_loss: 0.6726 - val_accuracy: 0.7600\n",
      "Epoch 650/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4927 - accuracy: 0.8824 - val_loss: 0.6716 - val_accuracy: 0.7600\n",
      "Epoch 651/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4922 - accuracy: 0.9020 - val_loss: 0.6707 - val_accuracy: 0.7600\n",
      "Epoch 652/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.4913 - accuracy: 0.9020 - val_loss: 0.6703 - val_accuracy: 0.7600\n",
      "Epoch 653/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4908 - accuracy: 0.8824 - val_loss: 0.6701 - val_accuracy: 0.7600\n",
      "Epoch 654/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4901 - accuracy: 0.8824 - val_loss: 0.6702 - val_accuracy: 0.7600\n",
      "Epoch 655/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4895 - accuracy: 0.8824 - val_loss: 0.6702 - val_accuracy: 0.7600\n",
      "Epoch 656/2000\n",
      "51/51 [==============================] - 0s 921us/sample - loss: 0.4889 - accuracy: 0.8824 - val_loss: 0.6693 - val_accuracy: 0.7600\n",
      "Epoch 657/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.4881 - accuracy: 0.8824 - val_loss: 0.6686 - val_accuracy: 0.7600\n",
      "Epoch 658/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4875 - accuracy: 0.8824 - val_loss: 0.6674 - val_accuracy: 0.7600\n",
      "Epoch 659/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4868 - accuracy: 0.9020 - val_loss: 0.6667 - val_accuracy: 0.7600\n",
      "Epoch 660/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4861 - accuracy: 0.9020 - val_loss: 0.6665 - val_accuracy: 0.7600\n",
      "Epoch 661/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4857 - accuracy: 0.9020 - val_loss: 0.6668 - val_accuracy: 0.7600\n",
      "Epoch 662/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.4848 - accuracy: 0.9020 - val_loss: 0.6667 - val_accuracy: 0.7600\n",
      "Epoch 663/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 981us/sample - loss: 0.4844 - accuracy: 0.9020 - val_loss: 0.6668 - val_accuracy: 0.7600\n",
      "Epoch 664/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4834 - accuracy: 0.9020 - val_loss: 0.6658 - val_accuracy: 0.7600\n",
      "Epoch 665/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4828 - accuracy: 0.9020 - val_loss: 0.6653 - val_accuracy: 0.7600\n",
      "Epoch 666/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4820 - accuracy: 0.9020 - val_loss: 0.6652 - val_accuracy: 0.7600\n",
      "Epoch 667/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4817 - accuracy: 0.9020 - val_loss: 0.6653 - val_accuracy: 0.7600\n",
      "Epoch 668/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4807 - accuracy: 0.9020 - val_loss: 0.6658 - val_accuracy: 0.7600\n",
      "Epoch 669/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4800 - accuracy: 0.9020 - val_loss: 0.6668 - val_accuracy: 0.7600\n",
      "Epoch 670/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.84 - 0s 1ms/sample - loss: 0.4801 - accuracy: 0.8824 - val_loss: 0.6679 - val_accuracy: 0.7600\n",
      "Epoch 671/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4791 - accuracy: 0.8824 - val_loss: 0.6675 - val_accuracy: 0.7600\n",
      "Epoch 672/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.4787 - accuracy: 0.8824 - val_loss: 0.6661 - val_accuracy: 0.7600\n",
      "Epoch 673/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4775 - accuracy: 0.8824 - val_loss: 0.6655 - val_accuracy: 0.7600\n",
      "Epoch 674/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.4772 - accuracy: 0.8824 - val_loss: 0.6647 - val_accuracy: 0.7600\n",
      "Epoch 675/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4763 - accuracy: 0.8824 - val_loss: 0.6631 - val_accuracy: 0.7600\n",
      "Epoch 676/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4756 - accuracy: 0.9020 - val_loss: 0.6621 - val_accuracy: 0.7600\n",
      "Epoch 677/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.4750 - accuracy: 0.9020 - val_loss: 0.6612 - val_accuracy: 0.7600\n",
      "Epoch 678/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.4745 - accuracy: 0.9020 - val_loss: 0.6598 - val_accuracy: 0.7600\n",
      "Epoch 679/2000\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.4739 - accuracy: 0.9020 - val_loss: 0.6591 - val_accuracy: 0.7600\n",
      "Epoch 680/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.4735 - accuracy: 0.9020 - val_loss: 0.6589 - val_accuracy: 0.7600\n",
      "Epoch 681/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4727 - accuracy: 0.9020 - val_loss: 0.6579 - val_accuracy: 0.7600\n",
      "Epoch 682/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4720 - accuracy: 0.9020 - val_loss: 0.6576 - val_accuracy: 0.7600\n",
      "Epoch 683/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4715 - accuracy: 0.9020 - val_loss: 0.6575 - val_accuracy: 0.7600\n",
      "Epoch 684/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4707 - accuracy: 0.9020 - val_loss: 0.6578 - val_accuracy: 0.7600\n",
      "Epoch 685/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4704 - accuracy: 0.9020 - val_loss: 0.6579 - val_accuracy: 0.7600\n",
      "Epoch 686/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.4694 - accuracy: 0.9020 - val_loss: 0.6590 - val_accuracy: 0.7600\n",
      "Epoch 687/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4687 - accuracy: 0.9020 - val_loss: 0.6600 - val_accuracy: 0.7600\n",
      "Epoch 688/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.4684 - accuracy: 0.9020 - val_loss: 0.6610 - val_accuracy: 0.7600\n",
      "Epoch 689/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.4675 - accuracy: 0.9020 - val_loss: 0.6612 - val_accuracy: 0.7600\n",
      "Epoch 690/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4672 - accuracy: 0.8824 - val_loss: 0.6615 - val_accuracy: 0.7600\n",
      "Epoch 691/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4665 - accuracy: 0.8824 - val_loss: 0.6607 - val_accuracy: 0.7600\n",
      "Epoch 692/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.4658 - accuracy: 0.9020 - val_loss: 0.6596 - val_accuracy: 0.7600\n",
      "Epoch 693/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4653 - accuracy: 0.9020 - val_loss: 0.6589 - val_accuracy: 0.7600\n",
      "Epoch 694/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4647 - accuracy: 0.9020 - val_loss: 0.6578 - val_accuracy: 0.7600\n",
      "Epoch 695/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4639 - accuracy: 0.9020 - val_loss: 0.6556 - val_accuracy: 0.7600\n",
      "Epoch 696/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.4635 - accuracy: 0.9020 - val_loss: 0.6541 - val_accuracy: 0.7600\n",
      "Epoch 697/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4630 - accuracy: 0.9020 - val_loss: 0.6530 - val_accuracy: 0.7600\n",
      "Epoch 698/2000\n",
      "51/51 [==============================] - 0s 942us/sample - loss: 0.4627 - accuracy: 0.9020 - val_loss: 0.6523 - val_accuracy: 0.7600\n",
      "Epoch 699/2000\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 0.4623 - accuracy: 0.9020 - val_loss: 0.6510 - val_accuracy: 0.7600\n",
      "Epoch 700/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4617 - accuracy: 0.9020 - val_loss: 0.6508 - val_accuracy: 0.7600\n",
      "Epoch 701/2000\n",
      "51/51 [==============================] - 0s 981us/sample - loss: 0.4609 - accuracy: 0.9020 - val_loss: 0.6513 - val_accuracy: 0.7600\n",
      "Epoch 702/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4602 - accuracy: 0.9020 - val_loss: 0.6522 - val_accuracy: 0.7600\n",
      "Epoch 703/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4594 - accuracy: 0.9020 - val_loss: 0.6528 - val_accuracy: 0.7600\n",
      "Epoch 704/2000\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.4586 - accuracy: 0.9020 - val_loss: 0.6536 - val_accuracy: 0.7600\n",
      "Epoch 705/2000\n",
      "51/51 [==============================] - 0s 961us/sample - loss: 0.4580 - accuracy: 0.9020 - val_loss: 0.6544 - val_accuracy: 0.7600\n",
      "Epoch 706/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4575 - accuracy: 0.9020 - val_loss: 0.6549 - val_accuracy: 0.7600\n",
      "Epoch 707/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4574 - accuracy: 0.9020 - val_loss: 0.6551 - val_accuracy: 0.7600\n",
      "Epoch 708/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4566 - accuracy: 0.9020 - val_loss: 0.6537 - val_accuracy: 0.7600\n",
      "Epoch 709/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4559 - accuracy: 0.9020 - val_loss: 0.6530 - val_accuracy: 0.7600\n",
      "Epoch 710/2000\n",
      "51/51 [==============================] - 0s 668us/sample - loss: 0.4552 - accuracy: 0.9020 - val_loss: 0.6522 - val_accuracy: 0.7600\n",
      "Epoch 711/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4547 - accuracy: 0.9020 - val_loss: 0.6515 - val_accuracy: 0.7600\n",
      "Epoch 712/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4545 - accuracy: 0.9020 - val_loss: 0.6511 - val_accuracy: 0.7600\n",
      "Epoch 713/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4536 - accuracy: 0.9020 - val_loss: 0.6497 - val_accuracy: 0.7600\n",
      "Epoch 714/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4531 - accuracy: 0.9020 - val_loss: 0.6489 - val_accuracy: 0.7600\n",
      "Epoch 715/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4526 - accuracy: 0.9020 - val_loss: 0.6484 - val_accuracy: 0.7600\n",
      "Epoch 716/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4518 - accuracy: 0.9020 - val_loss: 0.6487 - val_accuracy: 0.7600\n",
      "Epoch 717/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4514 - accuracy: 0.9020 - val_loss: 0.6490 - val_accuracy: 0.7600\n",
      "Epoch 718/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4507 - accuracy: 0.9020 - val_loss: 0.6489 - val_accuracy: 0.7600\n",
      "Epoch 719/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.4501 - accuracy: 0.9020 - val_loss: 0.6490 - val_accuracy: 0.7600\n",
      "Epoch 720/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4496 - accuracy: 0.9020 - val_loss: 0.6495 - val_accuracy: 0.7600\n",
      "Epoch 721/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.4489 - accuracy: 0.9020 - val_loss: 0.6500 - val_accuracy: 0.7600\n",
      "Epoch 722/2000\n",
      "51/51 [==============================] - 0s 589us/sample - loss: 0.4490 - accuracy: 0.9020 - val_loss: 0.6509 - val_accuracy: 0.7600\n",
      "Epoch 723/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.4482 - accuracy: 0.9020 - val_loss: 0.6506 - val_accuracy: 0.7600\n",
      "Epoch 724/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4475 - accuracy: 0.9020 - val_loss: 0.6490 - val_accuracy: 0.7600\n",
      "Epoch 725/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4468 - accuracy: 0.9020 - val_loss: 0.6480 - val_accuracy: 0.7600\n",
      "Epoch 726/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4463 - accuracy: 0.9020 - val_loss: 0.6468 - val_accuracy: 0.7600\n",
      "Epoch 727/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4456 - accuracy: 0.9020 - val_loss: 0.6454 - val_accuracy: 0.7600\n",
      "Epoch 728/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4452 - accuracy: 0.9020 - val_loss: 0.6443 - val_accuracy: 0.7600\n",
      "Epoch 729/2000\n",
      "51/51 [==============================] - 0s 745us/sample - loss: 0.4446 - accuracy: 0.9020 - val_loss: 0.6430 - val_accuracy: 0.7600\n",
      "Epoch 730/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4441 - accuracy: 0.9020 - val_loss: 0.6418 - val_accuracy: 0.7600\n",
      "Epoch 731/2000\n",
      "51/51 [==============================] - 0s 647us/sample - loss: 0.4436 - accuracy: 0.9020 - val_loss: 0.6414 - val_accuracy: 0.7600\n",
      "Epoch 732/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4431 - accuracy: 0.9020 - val_loss: 0.6407 - val_accuracy: 0.7600\n",
      "Epoch 733/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4426 - accuracy: 0.9020 - val_loss: 0.6407 - val_accuracy: 0.7600\n",
      "Epoch 734/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4418 - accuracy: 0.9020 - val_loss: 0.6416 - val_accuracy: 0.7600\n",
      "Epoch 735/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4418 - accuracy: 0.9020 - val_loss: 0.6426 - val_accuracy: 0.7600\n",
      "Epoch 736/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4410 - accuracy: 0.9020 - val_loss: 0.6426 - val_accuracy: 0.7600\n",
      "Epoch 737/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4404 - accuracy: 0.9020 - val_loss: 0.6429 - val_accuracy: 0.7600\n",
      "Epoch 738/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4400 - accuracy: 0.9020 - val_loss: 0.6429 - val_accuracy: 0.7600\n",
      "Epoch 739/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4395 - accuracy: 0.9020 - val_loss: 0.6425 - val_accuracy: 0.7600\n",
      "Epoch 740/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4387 - accuracy: 0.9020 - val_loss: 0.6413 - val_accuracy: 0.7600\n",
      "Epoch 741/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4383 - accuracy: 0.9020 - val_loss: 0.6404 - val_accuracy: 0.7600\n",
      "Epoch 742/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4384 - accuracy: 0.9216 - val_loss: 0.6392 - val_accuracy: 0.7600\n",
      "Epoch 743/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4373 - accuracy: 0.9216 - val_loss: 0.6390 - val_accuracy: 0.7600\n",
      "Epoch 744/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4368 - accuracy: 0.9216 - val_loss: 0.6387 - val_accuracy: 0.7600\n",
      "Epoch 745/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.4364 - accuracy: 0.9216 - val_loss: 0.6380 - val_accuracy: 0.7600\n",
      "Epoch 746/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4358 - accuracy: 0.9216 - val_loss: 0.6379 - val_accuracy: 0.7600\n",
      "Epoch 747/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4358 - accuracy: 0.9216 - val_loss: 0.6387 - val_accuracy: 0.7600\n",
      "Epoch 748/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4347 - accuracy: 0.9216 - val_loss: 0.6386 - val_accuracy: 0.7600\n",
      "Epoch 749/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.4342 - accuracy: 0.9216 - val_loss: 0.6380 - val_accuracy: 0.7600\n",
      "Epoch 750/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4338 - accuracy: 0.9216 - val_loss: 0.6376 - val_accuracy: 0.7600\n",
      "Epoch 751/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.4331 - accuracy: 0.9216 - val_loss: 0.6379 - val_accuracy: 0.7600\n",
      "Epoch 752/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.4327 - accuracy: 0.9216 - val_loss: 0.6386 - val_accuracy: 0.7600\n",
      "Epoch 753/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4325 - accuracy: 0.9216 - val_loss: 0.6389 - val_accuracy: 0.7600\n",
      "Epoch 754/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4317 - accuracy: 0.9216 - val_loss: 0.6381 - val_accuracy: 0.7600\n",
      "Epoch 755/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4311 - accuracy: 0.9216 - val_loss: 0.6368 - val_accuracy: 0.7600\n",
      "Epoch 756/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4306 - accuracy: 0.9216 - val_loss: 0.6355 - val_accuracy: 0.7600\n",
      "Epoch 757/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.4300 - accuracy: 0.9216 - val_loss: 0.6341 - val_accuracy: 0.7600\n",
      "Epoch 758/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4295 - accuracy: 0.9216 - val_loss: 0.6327 - val_accuracy: 0.7600\n",
      "Epoch 759/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4291 - accuracy: 0.9216 - val_loss: 0.6313 - val_accuracy: 0.7600\n",
      "Epoch 760/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4289 - accuracy: 0.9216 - val_loss: 0.6303 - val_accuracy: 0.7600\n",
      "Epoch 761/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4283 - accuracy: 0.9216 - val_loss: 0.6301 - val_accuracy: 0.7600\n",
      "Epoch 762/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4279 - accuracy: 0.9216 - val_loss: 0.6300 - val_accuracy: 0.7600\n",
      "Epoch 763/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.4273 - accuracy: 0.9216 - val_loss: 0.6297 - val_accuracy: 0.7600\n",
      "Epoch 764/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4270 - accuracy: 0.9216 - val_loss: 0.6293 - val_accuracy: 0.7600\n",
      "Epoch 765/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4263 - accuracy: 0.9216 - val_loss: 0.6285 - val_accuracy: 0.7600\n",
      "Epoch 766/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4257 - accuracy: 0.9216 - val_loss: 0.6282 - val_accuracy: 0.7600\n",
      "Epoch 767/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4258 - accuracy: 0.9216 - val_loss: 0.6281 - val_accuracy: 0.7600\n",
      "Epoch 768/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4250 - accuracy: 0.9216 - val_loss: 0.6280 - val_accuracy: 0.7600\n",
      "Epoch 769/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4243 - accuracy: 0.9216 - val_loss: 0.6279 - val_accuracy: 0.7600\n",
      "Epoch 770/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4237 - accuracy: 0.9216 - val_loss: 0.6282 - val_accuracy: 0.7600\n",
      "Epoch 771/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4231 - accuracy: 0.9216 - val_loss: 0.6283 - val_accuracy: 0.7600\n",
      "Epoch 772/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4230 - accuracy: 0.9216 - val_loss: 0.6285 - val_accuracy: 0.7600\n",
      "Epoch 773/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4222 - accuracy: 0.9216 - val_loss: 0.6295 - val_accuracy: 0.7600\n",
      "Epoch 774/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4218 - accuracy: 0.9216 - val_loss: 0.6304 - val_accuracy: 0.7600\n",
      "Epoch 775/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.4213 - accuracy: 0.9216 - val_loss: 0.6309 - val_accuracy: 0.7600\n",
      "Epoch 776/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4209 - accuracy: 0.9020 - val_loss: 0.6313 - val_accuracy: 0.7600\n",
      "Epoch 777/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4203 - accuracy: 0.9020 - val_loss: 0.6310 - val_accuracy: 0.7600\n",
      "Epoch 778/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4199 - accuracy: 0.9020 - val_loss: 0.6301 - val_accuracy: 0.7600\n",
      "Epoch 779/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4194 - accuracy: 0.9020 - val_loss: 0.6288 - val_accuracy: 0.7600\n",
      "Epoch 780/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4190 - accuracy: 0.9216 - val_loss: 0.6276 - val_accuracy: 0.7600\n",
      "Epoch 781/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4185 - accuracy: 0.9216 - val_loss: 0.6270 - val_accuracy: 0.7600\n",
      "Epoch 782/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4179 - accuracy: 0.9216 - val_loss: 0.6264 - val_accuracy: 0.7600\n",
      "Epoch 783/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.4176 - accuracy: 0.9216 - val_loss: 0.6265 - val_accuracy: 0.7600\n",
      "Epoch 784/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4171 - accuracy: 0.9216 - val_loss: 0.6258 - val_accuracy: 0.7600\n",
      "Epoch 785/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4166 - accuracy: 0.9216 - val_loss: 0.6259 - val_accuracy: 0.7600\n",
      "Epoch 786/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4163 - accuracy: 0.9412 - val_loss: 0.6253 - val_accuracy: 0.7600\n",
      "Epoch 787/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4158 - accuracy: 0.9412 - val_loss: 0.6250 - val_accuracy: 0.7600\n",
      "Epoch 788/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4153 - accuracy: 0.9412 - val_loss: 0.6240 - val_accuracy: 0.7600\n",
      "Epoch 789/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4150 - accuracy: 0.9216 - val_loss: 0.6236 - val_accuracy: 0.7600\n",
      "Epoch 790/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.4142 - accuracy: 0.9216 - val_loss: 0.6237 - val_accuracy: 0.7600\n",
      "Epoch 791/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4139 - accuracy: 0.9216 - val_loss: 0.6238 - val_accuracy: 0.7600\n",
      "Epoch 792/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4137 - accuracy: 0.9216 - val_loss: 0.6241 - val_accuracy: 0.7600\n",
      "Epoch 793/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.4130 - accuracy: 0.9216 - val_loss: 0.6249 - val_accuracy: 0.7600\n",
      "Epoch 794/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4124 - accuracy: 0.9216 - val_loss: 0.6251 - val_accuracy: 0.7600\n",
      "Epoch 795/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4120 - accuracy: 0.9216 - val_loss: 0.6252 - val_accuracy: 0.7600\n",
      "Epoch 796/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4116 - accuracy: 0.9216 - val_loss: 0.6252 - val_accuracy: 0.7600\n",
      "Epoch 797/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4113 - accuracy: 0.9216 - val_loss: 0.6246 - val_accuracy: 0.7600\n",
      "Epoch 798/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4108 - accuracy: 0.9412 - val_loss: 0.6231 - val_accuracy: 0.7600\n",
      "Epoch 799/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.4103 - accuracy: 0.9412 - val_loss: 0.6220 - val_accuracy: 0.7600\n",
      "Epoch 800/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.4097 - accuracy: 0.9216 - val_loss: 0.6215 - val_accuracy: 0.7600\n",
      "Epoch 801/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4095 - accuracy: 0.9216 - val_loss: 0.6209 - val_accuracy: 0.7600\n",
      "Epoch 802/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4089 - accuracy: 0.9216 - val_loss: 0.6205 - val_accuracy: 0.7600\n",
      "Epoch 803/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.90 - 0s 785us/sample - loss: 0.4085 - accuracy: 0.9216 - val_loss: 0.6207 - val_accuracy: 0.7600\n",
      "Epoch 804/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4080 - accuracy: 0.9216 - val_loss: 0.6203 - val_accuracy: 0.7600\n",
      "Epoch 805/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.4075 - accuracy: 0.9216 - val_loss: 0.6201 - val_accuracy: 0.7600\n",
      "Epoch 806/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.4072 - accuracy: 0.9216 - val_loss: 0.6200 - val_accuracy: 0.7600\n",
      "Epoch 807/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.4067 - accuracy: 0.9216 - val_loss: 0.6201 - val_accuracy: 0.7600\n",
      "Epoch 808/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.4063 - accuracy: 0.9216 - val_loss: 0.6209 - val_accuracy: 0.7600\n",
      "Epoch 809/2000\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.87 - 0s 785us/sample - loss: 0.4056 - accuracy: 0.9216 - val_loss: 0.6219 - val_accuracy: 0.7600\n",
      "Epoch 810/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4052 - accuracy: 0.9216 - val_loss: 0.6233 - val_accuracy: 0.7600\n",
      "Epoch 811/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.4052 - accuracy: 0.9412 - val_loss: 0.6245 - val_accuracy: 0.7600\n",
      "Epoch 812/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4047 - accuracy: 0.9412 - val_loss: 0.6242 - val_accuracy: 0.7600\n",
      "Epoch 813/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4045 - accuracy: 0.9412 - val_loss: 0.6238 - val_accuracy: 0.7600\n",
      "Epoch 814/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.4040 - accuracy: 0.9412 - val_loss: 0.6223 - val_accuracy: 0.7600\n",
      "Epoch 815/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.4033 - accuracy: 0.9412 - val_loss: 0.6212 - val_accuracy: 0.7600\n",
      "Epoch 816/2000\n",
      "51/51 [==============================] - 0s 766us/sample - loss: 0.4026 - accuracy: 0.9412 - val_loss: 0.6195 - val_accuracy: 0.7600\n",
      "Epoch 817/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4022 - accuracy: 0.9412 - val_loss: 0.6184 - val_accuracy: 0.7600\n",
      "Epoch 818/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.4022 - accuracy: 0.9216 - val_loss: 0.6163 - val_accuracy: 0.7600\n",
      "Epoch 819/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.4015 - accuracy: 0.9216 - val_loss: 0.6155 - val_accuracy: 0.7600\n",
      "Epoch 820/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.4013 - accuracy: 0.9216 - val_loss: 0.6151 - val_accuracy: 0.7600\n",
      "Epoch 821/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.4010 - accuracy: 0.9216 - val_loss: 0.6149 - val_accuracy: 0.7600\n",
      "Epoch 822/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.4007 - accuracy: 0.9216 - val_loss: 0.6151 - val_accuracy: 0.7600\n",
      "Epoch 823/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.4002 - accuracy: 0.9216 - val_loss: 0.6149 - val_accuracy: 0.7600\n",
      "Epoch 824/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3996 - accuracy: 0.9216 - val_loss: 0.6153 - val_accuracy: 0.7600\n",
      "Epoch 825/2000\n",
      "51/51 [==============================] - 0s 647us/sample - loss: 0.3990 - accuracy: 0.9216 - val_loss: 0.6163 - val_accuracy: 0.7600\n",
      "Epoch 826/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3984 - accuracy: 0.9216 - val_loss: 0.6174 - val_accuracy: 0.7600\n",
      "Epoch 827/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3980 - accuracy: 0.9216 - val_loss: 0.6185 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.3975 - accuracy: 0.9412 - val_loss: 0.6189 - val_accuracy: 0.7600\n",
      "Epoch 829/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3970 - accuracy: 0.9412 - val_loss: 0.6200 - val_accuracy: 0.7600\n",
      "Epoch 830/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3968 - accuracy: 0.9412 - val_loss: 0.6208 - val_accuracy: 0.7600\n",
      "Epoch 831/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3964 - accuracy: 0.9412 - val_loss: 0.6214 - val_accuracy: 0.7600\n",
      "Epoch 832/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3962 - accuracy: 0.9412 - val_loss: 0.6220 - val_accuracy: 0.7600\n",
      "Epoch 833/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.3964 - accuracy: 0.9412 - val_loss: 0.6220 - val_accuracy: 0.7600\n",
      "Epoch 834/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3956 - accuracy: 0.9412 - val_loss: 0.6207 - val_accuracy: 0.7600\n",
      "Epoch 835/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3956 - accuracy: 0.9412 - val_loss: 0.6187 - val_accuracy: 0.7600\n",
      "Epoch 836/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3943 - accuracy: 0.9412 - val_loss: 0.6177 - val_accuracy: 0.7600\n",
      "Epoch 837/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3938 - accuracy: 0.9412 - val_loss: 0.6168 - val_accuracy: 0.7600\n",
      "Epoch 838/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3933 - accuracy: 0.9412 - val_loss: 0.6157 - val_accuracy: 0.7600\n",
      "Epoch 839/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3932 - accuracy: 0.9412 - val_loss: 0.6149 - val_accuracy: 0.7600\n",
      "Epoch 840/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3926 - accuracy: 0.9412 - val_loss: 0.6141 - val_accuracy: 0.7600\n",
      "Epoch 841/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3923 - accuracy: 0.9412 - val_loss: 0.6139 - val_accuracy: 0.7600\n",
      "Epoch 842/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3920 - accuracy: 0.9412 - val_loss: 0.6132 - val_accuracy: 0.7600\n",
      "Epoch 843/2000\n",
      "51/51 [==============================] - 0s 647us/sample - loss: 0.3914 - accuracy: 0.9412 - val_loss: 0.6134 - val_accuracy: 0.7600\n",
      "Epoch 844/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3910 - accuracy: 0.9412 - val_loss: 0.6136 - val_accuracy: 0.7600\n",
      "Epoch 845/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3906 - accuracy: 0.9412 - val_loss: 0.6143 - val_accuracy: 0.7600\n",
      "Epoch 846/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3910 - accuracy: 0.9216 - val_loss: 0.6151 - val_accuracy: 0.7600\n",
      "Epoch 847/2000\n",
      "51/51 [==============================] - 0s 805us/sample - loss: 0.3899 - accuracy: 0.9216 - val_loss: 0.6143 - val_accuracy: 0.7600\n",
      "Epoch 848/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.3893 - accuracy: 0.9412 - val_loss: 0.6136 - val_accuracy: 0.7600\n",
      "Epoch 849/2000\n",
      "51/51 [==============================] - 0s 922us/sample - loss: 0.3890 - accuracy: 0.9412 - val_loss: 0.6130 - val_accuracy: 0.7600\n",
      "Epoch 850/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3886 - accuracy: 0.9412 - val_loss: 0.6121 - val_accuracy: 0.7600\n",
      "Epoch 851/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3881 - accuracy: 0.9412 - val_loss: 0.6107 - val_accuracy: 0.7600\n",
      "Epoch 852/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3877 - accuracy: 0.9608 - val_loss: 0.6098 - val_accuracy: 0.7600\n",
      "Epoch 853/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3876 - accuracy: 0.9608 - val_loss: 0.6090 - val_accuracy: 0.7600\n",
      "Epoch 854/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3871 - accuracy: 0.9608 - val_loss: 0.6084 - val_accuracy: 0.7600\n",
      "Epoch 855/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3868 - accuracy: 0.9608 - val_loss: 0.6085 - val_accuracy: 0.7600\n",
      "Epoch 856/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3864 - accuracy: 0.9608 - val_loss: 0.6091 - val_accuracy: 0.7600\n",
      "Epoch 857/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3859 - accuracy: 0.9608 - val_loss: 0.6094 - val_accuracy: 0.7600\n",
      "Epoch 858/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3855 - accuracy: 0.9412 - val_loss: 0.6093 - val_accuracy: 0.7600\n",
      "Epoch 859/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3853 - accuracy: 0.9412 - val_loss: 0.6088 - val_accuracy: 0.7600\n",
      "Epoch 860/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3843 - accuracy: 0.9412 - val_loss: 0.6095 - val_accuracy: 0.7600\n",
      "Epoch 861/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3844 - accuracy: 0.9412 - val_loss: 0.6104 - val_accuracy: 0.7600\n",
      "Epoch 862/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.3838 - accuracy: 0.9412 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 863/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3836 - accuracy: 0.9412 - val_loss: 0.6108 - val_accuracy: 0.8000\n",
      "Epoch 864/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.3833 - accuracy: 0.9412 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 865/2000\n",
      "51/51 [==============================] - 0s 883us/sample - loss: 0.3828 - accuracy: 0.9412 - val_loss: 0.6100 - val_accuracy: 0.8000\n",
      "Epoch 866/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3825 - accuracy: 0.9412 - val_loss: 0.6084 - val_accuracy: 0.8000\n",
      "Epoch 867/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3821 - accuracy: 0.9412 - val_loss: 0.6075 - val_accuracy: 0.7600\n",
      "Epoch 868/2000\n",
      "51/51 [==============================] - 0s 608us/sample - loss: 0.3815 - accuracy: 0.9412 - val_loss: 0.6068 - val_accuracy: 0.7600\n",
      "Epoch 869/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.3811 - accuracy: 0.9412 - val_loss: 0.6057 - val_accuracy: 0.7600\n",
      "Epoch 870/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.3805 - accuracy: 0.9412 - val_loss: 0.6053 - val_accuracy: 0.7600\n",
      "Epoch 871/2000\n",
      "51/51 [==============================] - 0s 804us/sample - loss: 0.3803 - accuracy: 0.9412 - val_loss: 0.6046 - val_accuracy: 0.7600\n",
      "Epoch 872/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3799 - accuracy: 0.9412 - val_loss: 0.6036 - val_accuracy: 0.7600\n",
      "Epoch 873/2000\n",
      "51/51 [==============================] - 0s 863us/sample - loss: 0.3799 - accuracy: 0.9608 - val_loss: 0.6033 - val_accuracy: 0.7600\n",
      "Epoch 874/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3795 - accuracy: 0.9608 - val_loss: 0.6038 - val_accuracy: 0.7600\n",
      "Epoch 875/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3793 - accuracy: 0.9608 - val_loss: 0.6041 - val_accuracy: 0.7600\n",
      "Epoch 876/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3787 - accuracy: 0.9608 - val_loss: 0.6040 - val_accuracy: 0.7600\n",
      "Epoch 877/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3785 - accuracy: 0.9608 - val_loss: 0.6035 - val_accuracy: 0.7600\n",
      "Epoch 878/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.3780 - accuracy: 0.9608 - val_loss: 0.6035 - val_accuracy: 0.7600\n",
      "Epoch 879/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3776 - accuracy: 0.9608 - val_loss: 0.6037 - val_accuracy: 0.7600\n",
      "Epoch 880/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3770 - accuracy: 0.9412 - val_loss: 0.6039 - val_accuracy: 0.7600\n",
      "Epoch 881/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3769 - accuracy: 0.9412 - val_loss: 0.6043 - val_accuracy: 0.7600\n",
      "Epoch 882/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3763 - accuracy: 0.9412 - val_loss: 0.6044 - val_accuracy: 0.7600\n",
      "Epoch 883/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3760 - accuracy: 0.9412 - val_loss: 0.6041 - val_accuracy: 0.7600\n",
      "Epoch 884/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3755 - accuracy: 0.9412 - val_loss: 0.6031 - val_accuracy: 0.7600\n",
      "Epoch 885/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3752 - accuracy: 0.9412 - val_loss: 0.6025 - val_accuracy: 0.7600\n",
      "Epoch 886/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3747 - accuracy: 0.9412 - val_loss: 0.6025 - val_accuracy: 0.7600\n",
      "Epoch 887/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3744 - accuracy: 0.9412 - val_loss: 0.6028 - val_accuracy: 0.7600\n",
      "Epoch 888/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3741 - accuracy: 0.9412 - val_loss: 0.6032 - val_accuracy: 0.8000\n",
      "Epoch 889/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3738 - accuracy: 0.9412 - val_loss: 0.6033 - val_accuracy: 0.8000\n",
      "Epoch 890/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3732 - accuracy: 0.9412 - val_loss: 0.6043 - val_accuracy: 0.8000\n",
      "Epoch 891/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3731 - accuracy: 0.9412 - val_loss: 0.6050 - val_accuracy: 0.7600\n",
      "Epoch 892/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3726 - accuracy: 0.9412 - val_loss: 0.6057 - val_accuracy: 0.7600\n",
      "Epoch 893/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3722 - accuracy: 0.9412 - val_loss: 0.6063 - val_accuracy: 0.7600\n",
      "Epoch 894/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3719 - accuracy: 0.9412 - val_loss: 0.6066 - val_accuracy: 0.7600\n",
      "Epoch 895/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3717 - accuracy: 0.9412 - val_loss: 0.6073 - val_accuracy: 0.7600\n",
      "Epoch 896/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3715 - accuracy: 0.9412 - val_loss: 0.6069 - val_accuracy: 0.7600\n",
      "Epoch 897/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3709 - accuracy: 0.9412 - val_loss: 0.6055 - val_accuracy: 0.7600\n",
      "Epoch 898/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.3705 - accuracy: 0.9412 - val_loss: 0.6044 - val_accuracy: 0.7600\n",
      "Epoch 899/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3701 - accuracy: 0.9412 - val_loss: 0.6037 - val_accuracy: 0.7600\n",
      "Epoch 900/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3697 - accuracy: 0.9412 - val_loss: 0.6026 - val_accuracy: 0.7600\n",
      "Epoch 901/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3695 - accuracy: 0.9412 - val_loss: 0.6012 - val_accuracy: 0.7600\n",
      "Epoch 902/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3690 - accuracy: 0.9412 - val_loss: 0.6005 - val_accuracy: 0.7600\n",
      "Epoch 903/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3686 - accuracy: 0.9412 - val_loss: 0.6000 - val_accuracy: 0.7600\n",
      "Epoch 904/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3684 - accuracy: 0.9412 - val_loss: 0.5994 - val_accuracy: 0.7600\n",
      "Epoch 905/2000\n",
      "51/51 [==============================] - 0s 647us/sample - loss: 0.3679 - accuracy: 0.9412 - val_loss: 0.5983 - val_accuracy: 0.7600\n",
      "Epoch 906/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3676 - accuracy: 0.9412 - val_loss: 0.5974 - val_accuracy: 0.7600\n",
      "Epoch 907/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3671 - accuracy: 0.9412 - val_loss: 0.5972 - val_accuracy: 0.8000\n",
      "Epoch 908/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.3669 - accuracy: 0.9412 - val_loss: 0.5972 - val_accuracy: 0.8000\n",
      "Epoch 909/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3666 - accuracy: 0.9412 - val_loss: 0.5964 - val_accuracy: 0.8000\n",
      "Epoch 910/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3663 - accuracy: 0.9412 - val_loss: 0.5961 - val_accuracy: 0.8000\n",
      "Epoch 911/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3663 - accuracy: 0.9412 - val_loss: 0.5955 - val_accuracy: 0.8000\n",
      "Epoch 912/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3654 - accuracy: 0.9412 - val_loss: 0.5958 - val_accuracy: 0.8000\n",
      "Epoch 913/2000\n",
      "51/51 [==============================] - 0s 608us/sample - loss: 0.3652 - accuracy: 0.9412 - val_loss: 0.5961 - val_accuracy: 0.8000\n",
      "Epoch 914/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3647 - accuracy: 0.9412 - val_loss: 0.5955 - val_accuracy: 0.8000\n",
      "Epoch 915/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3647 - accuracy: 0.9412 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
      "Epoch 916/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3641 - accuracy: 0.9412 - val_loss: 0.5935 - val_accuracy: 0.8000\n",
      "Epoch 917/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3636 - accuracy: 0.9412 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
      "Epoch 918/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3632 - accuracy: 0.9412 - val_loss: 0.5915 - val_accuracy: 0.8000\n",
      "Epoch 919/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3633 - accuracy: 0.9412 - val_loss: 0.5904 - val_accuracy: 0.8000\n",
      "Epoch 920/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3626 - accuracy: 0.9608 - val_loss: 0.5901 - val_accuracy: 0.8000\n",
      "Epoch 921/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3625 - accuracy: 0.9608 - val_loss: 0.5894 - val_accuracy: 0.8000\n",
      "Epoch 922/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3619 - accuracy: 0.9608 - val_loss: 0.5891 - val_accuracy: 0.8000\n",
      "Epoch 923/2000\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 0.3615 - accuracy: 0.9608 - val_loss: 0.5888 - val_accuracy: 0.8000\n",
      "Epoch 924/2000\n",
      "51/51 [==============================] - 0s 903us/sample - loss: 0.3616 - accuracy: 0.9608 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 925/2000\n",
      "51/51 [==============================] - 0s 824us/sample - loss: 0.3609 - accuracy: 0.9608 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
      "Epoch 926/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3606 - accuracy: 0.9412 - val_loss: 0.5908 - val_accuracy: 0.8000\n",
      "Epoch 927/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3603 - accuracy: 0.9412 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
      "Epoch 928/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3608 - accuracy: 0.9412 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
      "Epoch 929/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3596 - accuracy: 0.9412 - val_loss: 0.5923 - val_accuracy: 0.8000\n",
      "Epoch 930/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3592 - accuracy: 0.9412 - val_loss: 0.5919 - val_accuracy: 0.8000\n",
      "Epoch 931/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3588 - accuracy: 0.9412 - val_loss: 0.5916 - val_accuracy: 0.8000\n",
      "Epoch 932/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3584 - accuracy: 0.9412 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
      "Epoch 933/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3580 - accuracy: 0.9412 - val_loss: 0.5908 - val_accuracy: 0.8000\n",
      "Epoch 934/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.3577 - accuracy: 0.9412 - val_loss: 0.5905 - val_accuracy: 0.7600\n",
      "Epoch 935/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3575 - accuracy: 0.9608 - val_loss: 0.5903 - val_accuracy: 0.7600\n",
      "Epoch 936/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3573 - accuracy: 0.9608 - val_loss: 0.5908 - val_accuracy: 0.7600\n",
      "Epoch 937/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3569 - accuracy: 0.9608 - val_loss: 0.5908 - val_accuracy: 0.7600\n",
      "Epoch 938/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3567 - accuracy: 0.9608 - val_loss: 0.5905 - val_accuracy: 0.7600\n",
      "Epoch 939/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3565 - accuracy: 0.9608 - val_loss: 0.5898 - val_accuracy: 0.7600\n",
      "Epoch 940/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3561 - accuracy: 0.9608 - val_loss: 0.5887 - val_accuracy: 0.7600\n",
      "Epoch 941/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3565 - accuracy: 0.9608 - val_loss: 0.5870 - val_accuracy: 0.7600\n",
      "Epoch 942/2000\n",
      "51/51 [==============================] - 0s 687us/sample - loss: 0.3559 - accuracy: 0.9608 - val_loss: 0.5863 - val_accuracy: 0.7600\n",
      "Epoch 943/2000\n",
      "51/51 [==============================] - 0s 706us/sample - loss: 0.3556 - accuracy: 0.9608 - val_loss: 0.5853 - val_accuracy: 0.7600\n",
      "Epoch 944/2000\n",
      "51/51 [==============================] - 0s 746us/sample - loss: 0.3548 - accuracy: 0.9608 - val_loss: 0.5849 - val_accuracy: 0.7600\n",
      "Epoch 945/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3543 - accuracy: 0.9608 - val_loss: 0.5850 - val_accuracy: 0.7600\n",
      "Epoch 946/2000\n",
      "51/51 [==============================] - 0s 707us/sample - loss: 0.3546 - accuracy: 0.9608 - val_loss: 0.5852 - val_accuracy: 0.8000\n",
      "Epoch 947/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3536 - accuracy: 0.9608 - val_loss: 0.5847 - val_accuracy: 0.8000\n",
      "Epoch 948/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3533 - accuracy: 0.9608 - val_loss: 0.5848 - val_accuracy: 0.8000\n",
      "Epoch 949/2000\n",
      "51/51 [==============================] - 0s 765us/sample - loss: 0.3528 - accuracy: 0.9608 - val_loss: 0.5854 - val_accuracy: 0.8000\n",
      "Epoch 950/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3526 - accuracy: 0.9412 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 951/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3529 - accuracy: 0.9412 - val_loss: 0.5869 - val_accuracy: 0.8000\n",
      "Epoch 952/2000\n",
      "51/51 [==============================] - 0s 726us/sample - loss: 0.3524 - accuracy: 0.9412 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 953/2000\n",
      "51/51 [==============================] - 0s 648us/sample - loss: 0.3524 - accuracy: 0.9412 - val_loss: 0.5856 - val_accuracy: 0.8000\n",
      "Epoch 954/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3513 - accuracy: 0.9412 - val_loss: 0.5855 - val_accuracy: 0.8000\n",
      "Epoch 955/2000\n",
      "51/51 [==============================] - 0s 647us/sample - loss: 0.3512 - accuracy: 0.9412 - val_loss: 0.5857 - val_accuracy: 0.8000\n",
      "Epoch 956/2000\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.3508 - accuracy: 0.9412 - val_loss: 0.5856 - val_accuracy: 0.8000\n",
      "Epoch 957/2000\n",
      "51/51 [==============================] - 0s 667us/sample - loss: 0.3504 - accuracy: 0.9412 - val_loss: 0.5850 - val_accuracy: 0.8000\n",
      "Epoch 958/2000\n",
      "51/51 [==============================] - 0s 628us/sample - loss: 0.3502 - accuracy: 0.9608 - val_loss: 0.5849 - val_accuracy: 0.8000\n",
      "Epoch 959/2000\n",
      "32/51 [=================>............] - ETA: 0s - loss: 0.4107 - accuracy: 0.9375\n",
      "Reached 95% accuracy so cancelling training!\n",
      "51/51 [==============================] - 0s 785us/sample - loss: 0.3497 - accuracy: 0.9608 - val_loss: 0.5852 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs=2000,validation_data=(X_test,Y_test),callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testweights = []\n",
    "testprob = []\n",
    "for i in range(0,p,1):\n",
    "    if classifications[i,0] > classifications[i,1] and classifications[i,0] > classifications[i,2] and classifications[i,0] > classifications[i,3]:\n",
    "        testweights.append('0')\n",
    "        testprob.append(classifications[i,0])\n",
    "    elif classifications[i,1] > classifications[i,2] and classifications[i,1] > classifications[i,3]:\n",
    "        testweights.append('1')\n",
    "        testprob.append(classifications[i,1])\n",
    "    elif classifications[i,2] > classifications[i,3]:\n",
    "        testweights.append('2')\n",
    "        testprob.append(classifications[i,2])\n",
    "    else:\n",
    "        testweights.append('3')\n",
    "        testprob.append(classifications[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() \n",
    "  \n",
    "# Creating two columns \n",
    "df['Question'] = head\n",
    "df['Prob'] = testprob\n",
    "df['Difficulty'] = testweights \n",
    "\n",
    "# Converting to excel \n",
    "df.to_excel('result.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
